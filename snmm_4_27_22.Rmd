---
title: "Coarse SNNM: DIH Prosecutions"
author: "Kelly Kung"
date: "4/12/2022"
output: 
  html_document:
    toc: true
    toc_float: true
    number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_knit$set(echo = TRUE, root.dir = "~/OneDrive - Boston University/Research-Lok")
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
```

# Set Up
## R Code 
```{r}
#packages we need for this code file
library(ggplot2)
library(mgcv)
library(lubridate)
library(zoo)
library(tidyverse)
library(dplyr)
library(aod)
library("plot3D")
``` 

## Data 
```{r}
#read in data
main_analysis_data<-read.csv("./Data/full_data_set_11_29_21_unintentional.csv")

################################## set up data set ################################
#add the intervention dates and time period data
main_analysis_data$Intervention_First_Date<-as.Date(main_analysis_data$Intervention_First_Date)
main_analysis_data$Time_Period_Start<-as.Date(main_analysis_data$Time_Period_Start)
names(main_analysis_data)[which(colnames(main_analysis_data) == "sum_deaths")] <- "imputed_deaths"
main_analysis_data$dih_exposure <- as.numeric(main_analysis_data$Intervention_Redefined > 0)
#compute the risk of overdose death
main_analysis_data$prop_dead <- main_analysis_data$imputed_deaths/main_analysis_data$population

```

# Model for Treatment Effect
## Create Dataset
```{r}

#create sum of policies already enacted for treatment initiation
#create a new dataset dih_dataset for which we can make changes to
dih_dataset <- main_analysis_data
#we first create lag variables for the policies so that we know that by time t, whether the policy has been enacted
#note that we don't count what happened at time t
dih_dataset <- dih_dataset %>%
  #make sure that the data is ordered according to first state and then time period
  arrange(State, Time_Period_ID) %>%
  #group by state so that when we lag, we only lag within the state
  group_by(State) %>%
  mutate(lag_tx = lag(dih_exposure),
         lag_naloxone_pharm_yes = lag(Naloxone_Pharmacy_Yes_Redefined),
         lag_naloxone_pharm_no = lag(Naloxone_Pharmacy_No_Redefined),
         lag_medical_marijuana = lag(Medical_Marijuana_Redefined),
         lag_rec_marijuana = lag(Recreational_Marijuana_Redefined),
         lag_gsl = lag(GSL_Redefined),
         lag_pdmp = lag(PDMP_Redefined),
         lag_medicaid = lag(Medicaid_Expansion_Redefined),
         lag_intervention = lag(Intervention_Redefined),
         lag_prop_deaths = lag(imputed_deaths/population),
         lag_deaths = lag(imputed_deaths)) 

#we want to impute the lag number of deaths with the deaths from 1999 -- we can obtain from previous data cleaning work
drug_od_data <- read.csv("./Data/od_data_interpolated_unintentional_1999_2019_age_18_and_up_11_29_21.csv")
#group data by 6 months
drug_od_data_grouped <- drug_od_data %>%
  mutate(Date = as.Date(Date)) %>%
  mutate(Time_Period_Start = lubridate::floor_date(Date , "6 months" ))

#population for 1999 - obtained from NBER https://data.nber.org/data/census-intercensal-population/
pop_data <- read.csv("./Data/pop7099s.csv")
pop_1999 <- pop_data %>%
  filter(year == 1999,
         age >= 18) %>%
  group_by(state) %>%
  summarise(total_pop = sum(pop))

drug_od_data_grouped_1999<- drug_od_data_grouped %>% 
  filter(year(Time_Period_Start) == 1999) %>%
  group_by(State, Time_Period_Start) %>%
  summarise(sum_deaths = sum(interp_vals, na.rm = TRUE))

drug_od_w_pop <- merge(drug_od_data_grouped_1999, pop_1999,
                       by.x = "State", by.y = "state")

#pull out the interpolated deaths for July - December 1999
od_july_1999 <- drug_od_w_pop %>%
  filter(Time_Period_Start == "1999-07-01") %>%
  mutate(prop_death = sum_deaths/total_pop) %>%
  dplyr::select(State,
         sum_deaths,
         prop_death)


#make column of the lagged date
od_july_1999 <- od_july_1999 %>%
  mutate(lag_time_period_start = "2000-01-01")

#merge to original dataset
dih_dataset <- merge(dih_dataset, od_july_1999, 
                     by.x = c("State", "Time_Period_Start"), 
                     by.y = c("State", "lag_time_period_start"),
                     all.x = TRUE)

#fill in NA of lag_deaths with the sum_deaths and remove sum_deaths
dih_dataset <- dih_dataset %>%
  mutate(lag_deaths = coalesce(lag_deaths, sum_deaths),
         lag_prop_deaths = coalesce(lag_prop_deaths, prop_death)) %>%
  dplyr::select(-sum_deaths,
         -prop_death) %>%
  group_by(State) %>%
  mutate(lag_cum_sum_deaths = cumsum(lag_deaths),
         lag_cum_sum_prop_death = cumsum(lag_prop_deaths),
         log_prop_dead = log(prop_dead),
         log_lag_prop_death = log(lag_prop_deaths))

#since we lag the variables, the entry at time 1 will be NA. Since we have start dates of the different policies, I checked to 
#see which policies were enacted before Jan 1, 2000.
#if the policies were enacted before Jan 1, 2000, I impute a 1 for the first time period, otherwise a 0
dih_dataset$lag_tx[dih_dataset$Time_Period_ID == 1] <- 
  dih_dataset$lag_naloxone_pharm_yes[dih_dataset$Time_Period_ID == 1] <- 
  dih_dataset$lag_naloxone_pharm_no[dih_dataset$Time_Period_ID == 1] <-
  dih_dataset$lag_rec_marijuana[dih_dataset$Time_Period_ID == 1] <-
  dih_dataset$lag_gsl[dih_dataset$Time_Period_ID == 1] <-
  dih_dataset$lag_medicaid[dih_dataset$Time_Period_ID == 1] <- 
  dih_dataset$lag_intervention[dih_dataset$Time_Period_ID == 1]<-0

dih_dataset$lag_medical_marijuana[dih_dataset$Time_Period_ID == 1 &
                                   dih_dataset$State %in% 
                                   c("Alaska", "California", "Maine", "Oregon", "Washington")] <- 1
dih_dataset$lag_medical_marijuana[dih_dataset$Time_Period_ID == 1  &
                                   !(dih_dataset$State %in% 
                                       c("Alaska", "California", "Maine", "Oregon", "Washington"))] <- 0

dih_dataset$lag_pdmp[dih_dataset$Time_Period_ID == 1  &
                                   dih_dataset$State %in% 
                      c("California", "Hawaii", "Idaho", "Illinois", "Indiana", 
                        "Kentucky", "Massachusetts", "Michigan", "Nevada",
                        "New York", "Oklahoma", "Pennsylvania", "Rhode Island",
                        "Texas", "Utah", "West Virginia")] <- 1
dih_dataset$lag_pdmp[dih_dataset$Time_Period_ID == 1  &
                                   !(dih_dataset$State %in% 
                                       c("California", "Hawaii", "Idaho", "Illinois", "Indiana", 
                                         "Kentucky", "Massachusetts", "Michigan", "Nevada",
                                         "New York", "Oklahoma", "Pennsylvania", "Rhode Island",
                                         "Texas", "Utah", "West Virginia"))] <- 0

#create a new variable that indicates the number of policies that have been enacted by time t
dih_dataset$sum_lag_policies <- dih_dataset$lag_naloxone_pharm_yes + 
  dih_dataset$lag_naloxone_pharm_no + 
  dih_dataset$lag_medical_marijuana + 
  dih_dataset$lag_rec_marijuana + 
  dih_dataset$lag_gsl + 
  dih_dataset$lag_pdmp + 
  dih_dataset$lag_medicaid

#impute Hawaii's treatment date as something far off in the future
dih_dataset$Intervention_First_Date[dih_dataset$State == "Hawaii"] <- as.Date("9999-01-01")

```

# One Parameter Model: Binary Treatment Variable
## Mimicking Potential Outcomes
To compute the mimicked potential outcome: $H_{s,k}(t)$ for $k \in \{7-2019, \dotsc, 7-2000 \}$ and $t < k$, we first extract $Y_{s,k}$, where $Y_{s,k}$ is the log proportion of drug overdose death. We then compute $\gamma_t^k = exp(\psi*(a_{s,t} - a_{s,t-1}))$. Let $t_s^*$ be the treatment time interval for state $s$. We focus on data points for which $t \leq t_s^*$ and $t<k$. This is because for the treatment initiation model, we include data points for which $t \leq t_s^*$ and we want $t<k$. We let $a_{s,t}$ be a binary variable. For these data points we are intersted in, we create the variable `hkt` which is equal to $\frac{Y_{s,k}}{exp(\psi)}$ when $k > t_s^*$ (i.e. $Y_{s,k}$ is a treated outcome) and equal to $Y_{s,k}$ when $k \leq t_s^*$ (i.e. $Y_{s,k}$ is an untreated outcome). Lastly, we combine all these datapoints together for each $k$ into a dataset to be returned to use in the treatment initiation model.

```{r}

compute_mimick_potential_outcome <- function(dataFrame, gamma_k_t){
  #new_df is the dataset we will return, with the new rows appended
  #we initialize it first as the input dataset df
  new_data_frame <- data.frame()
  
  #here, k is the time in which we observe the outcome and t is the time of the treatments
  #so we have k > t
  for(k in max(unique(dataFrame$Time_Period_ID)):2){
    #we first pull out the risk of OD at time k, so Y_k
    outcome_k_data <- dataFrame %>%
      arrange(State) %>%
      filter(Time_Period_ID == k) %>%
      dplyr::select(State, prop_dead, Intervention_First_Date, Time_Period_Start)
    
    #pull the treatment time period for the first treatment date
    tx_time_period_data <- dataFrame %>%
      filter(Time_Period_Start == floor_date(Intervention_First_Date, "6 months")) %>%
      dplyr::select(State, Time_Period_ID)
    
    #rename the Time_Period_ID
    colnames(tx_time_period_data) <- c("State", "t_s")
    
    
    #merge it with outcome_k_data
    #note: we have all.x = TRUE because we want all the rows in outcome_k_data since the date
    #for Hawaii is set to year 9999, so there are no matches
    outcome_k_data_with_tx_time_period <- merge(outcome_k_data, tx_time_period_data, by = "State",
                                                all.x = TRUE)
    
    #set t_s for Hawaii to be 9999
    outcome_k_data_with_tx_time_period$t_s[outcome_k_data_with_tx_time_period$State == "Hawaii"] <- 9999
    
    #compute k - t_s^*
    outcome_k_data_with_tx_time_period$k_minus_t_s <- k - outcome_k_data_with_tx_time_period$t_s
    
    
    #compute H_k(t) given gamma_k_t:
    #here, let t^* = treatment time 
    #if k <= t^*, then H_k(t) = Y_k since we havent treated yet, so doesn't affect
    #if t^* < t < k, then H_k(t) = Y_k since a_{t} - a_{t-1} = 0
    #if t <= t^* < k, then H_k(t) = Y_k/gamma_k_t
    outcome_k_data_with_tx_time_period$hkt <- ifelse(outcome_k_data_with_tx_time_period$k_minus_t_s > 0,
                                                     outcome_k_data_with_tx_time_period$prop_dead/gamma_k_t, 
                                                     outcome_k_data_with_tx_time_period$prop_dead)
    
    # outcome_k_data <- dataFrame %>%
    #   +       arrange(State) %>%
    #   +       filter(Time_Period_ID == k) %>%
    #   +       dplyr::select(State, prop_dead, Intervention_First_Date, Time_Period_Start)
    # +     
    #   +     #compute H_k(t) given gamma_k_t:
    #   +     #here, let t^* = treatment time 
    #   +     #if k <= t^*, then H_k(t) = Y_k since we havent treated yet, so doesn't affect
    #   +     #if t^* < t < k, then H_k(t) = Y_k since a_{t} - a_{t-1} = 0
    #   +     #if t <= t^* < k, then H_k(t) = Y_k/gamma_k_t
    #   +     outcome_k_data$hkt <- ifelse(outcome_k_data$Time_Period_Start > outcome_k_data$Intervention_First_Date,
    #                                      +                                  outcome_k_data$prop_dead/gamma_k_t, outcome_k_data$prop_dead)
    
    
    #filter the data for which A_{s,t} = 0 and the time interval that contains the treatment time since we only need these data 
    #to predict treatment initiation for the model
    #we also filter so that the t < k
    untreated_and_first_tx_date_data <- dataFrame %>%
      arrange(State, Time_Period_ID) %>%
      #filter for t <= t^* because we use these time periods to predict treatment initiation
      filter(Time_Period_Start <= Intervention_First_Date,
             #filter for t < k
             Time_Period_ID < k)
    
    #merge the filtered dataset with the outcome_k_data_with_tx_time_period which contains the computed H_k(t)
    untreated_and_first_tx_date_data <- merge(untreated_and_first_tx_date_data, 
                                              outcome_k_data_with_tx_time_period[,c("State", "hkt", "t_s",
                                                                                    "k_minus_t_s")], by = "State")
    
    #compute values that may be useful
    #add k and t to the dataset and the date of k
    untreated_and_first_tx_date_data$k <- k
    untreated_and_first_tx_date_data$date_k <- unique(outcome_k_data_with_tx_time_period$Time_Period_Start)
    untreated_and_first_tx_date_data$t <- untreated_and_first_tx_date_data$Time_Period_ID
    
    
    #compute k - t
    untreated_and_first_tx_date_data$k_minus_t <- k - untreated_and_first_tx_date_data$t
    #compute indicator of whether Y_{s,k} is treated outcome
    untreated_and_first_tx_date_data$treated_outcome_indicator <- untreated_and_first_tx_date_data$date_k > 
      untreated_and_first_tx_date_data$Intervention_First_Date
    
    #we then append the rows to the new_data_frame
    new_data_frame <- rbind(new_data_frame, untreated_and_first_tx_date_data)
  }
  new_data_frame
}



```

## Finding $\psi$: $\gamma_t^k = exp(\psi (a_t - a_{t-1}))$
Here, we assume that the treatment effects model is given by the one parameter model:
$$\gamma_t^k = exp(\psi*(a_t - a_{t-1})),$$
where $a_t$ and $a_{t-1}$ are binary variables (for now) indicating whether there have ever been any DIH prosecution media alerts by time $t$ and $t-1$. Further, we have $k > t_s^*$.

We fit a treatment initiation model for the response `dih_exposure` which is a binary variable indicating whether the state was exposed to DIH prosecution in the media, where we use the following as predictors:

* `sum_lag_policies` is the number of other policy measures that have been enacted from time 1 until time $t-1$
* `hkt` is the computed $H_k(t)$
* `Time_Period_ID` is the linear time effect.

Recall that the `analysis_data_with_hkt` only contains the datapoints for which $t \leq t^*$.
For each value $\psi$, we extract the coefficient of `hkt` from the treatment initiation model, and we find the $\psi$ that leads to a coefficient of zero. 
We also store a vector of `confidence_interval` which stores the values of $\psi$ if the Wald test for the coefficient of `hkt` is not statistically significant at the $alpha = 0.05$ level.

```{r}
#create a vector of 100 psi
# psi_grid_params <- seq(-0.1012847, -0.1012846, length.out = 100)
# psi_grid_params <- seq(-.2, .1, by = 0.001)
psi_grid_params <- seq(-1, 1, by = .01)
 #initialize the vector of coefficients for H(t) in treatment initiation model
coef_hkt <- rep(NA, length(psi_grid_params))
confidence_interval <- c()
for(grid_point in 1:length(psi_grid_params)){
  #statement to print the status of the for loop
  # if(grid_point%%10 == 0){print(grid_point)}
  #compute gamma_k_t given the psi_grid_params[grid_point]. Since here, the treatment is binary, we only need the value for
  #exp(psi_grid_params[grid_point])
  gamma_k_t <- exp(psi_grid_params[grid_point])

  #compute H(t) given the dataset and gamma_k_t
  analysis_data_with_hkt <- compute_mimick_potential_outcome(dih_dataset, gamma_k_t)
 
  #fit model for treatment initiation
  treatment_initiation_model <- glm(dih_exposure~ 
                       sum_lag_policies + 
                       hkt +
                       log_lag_prop_death +   
                       Time_Period_ID,
                     data = analysis_data_with_hkt, family = "binomial")
  
  #store the coefficient for H_k(t)
  coef_hkt[grid_point] <- coef(treatment_initiation_model)["hkt"]
  
  #conduct the Wald Test for the third coefficient, which is H_k(t) here since the first coefficient is the intercept
  wald_test_results <- wald.test(vcov(treatment_initiation_model), coef(treatment_initiation_model), 3)
  #we then store the p-value and store the psi values if the p-value > 0.05
  pval <- wald_test_results$result$chi2["P"]
  if(pval > 0.05){
    confidence_interval <- rbind(confidence_interval, psi_grid_params[grid_point])
  }
}

# coef_hkt[90:91]
# psi_grid_params[90:91]
coef_hkt[87:88]
psi_grid_params[87:88]
as.vector(confidence_interval) 

#without past OD
#-0.022
#(-0.140, 0.083)

#with past OD
#-0.22
# (-0.40, -0.08)

#with past OD and probability of death in past
# -0.11 (-.21, -.02)

#with past OD and log probability of death in past
# 0.0066 (-0.0005 ,  0.0142)

#log probability past OD, Hkt is probability
# -0.1303734  (-0.25, -0.03)
```

When we did not include the past number of drug overdose deaths, the $\psi$ that produced an $\alpha(\psi)$, where $\alpha(\psi)$ is the coefficient of $H_k(t)$ in the treatment initiation model, that is closest to 0 is -0.022. The 95% Confidence Interval is (-0.140, 0.083).

When we included the past number of drug overdose deaths as the log of probability of drug overdose deaths into the treatment initiation model, the $\psi$ that produced an $\alpha(\psi)$, where $\alpha(\psi)$ is the coefficient of $H_k(t)$ in the treatment initiation model, that is closest to 0 is 0.0066. The 95% Confidence Interval is (-0.0005 ,  0.0142).


## Checking Grid-Search
Since we can compute the $\psi$ in a one-parameter model from the unbiased estimating equation, we do so to check the grid-search value.
We showed that 
$$E\left(\sum_s \sum_{k=1}^{T + 1} \sum_{t = 0}^{k-1} \vec{q}{_t}^{k}(\bar{X}_{s,t}, \bar{A}_{s,t-1}) H_{s,k}(t) \mathbb{I}\{\bar{A}_{s,t-1} = \bar{0}\}({g(A}_{s,t}) - \lambda_{s,t})\right) = 0.$$
We let $\vec{q}{_t}^{k}(\bar{X}_{s,t}, \bar{A}_{s,t-1}) = 1$ and $H_{s,k}(t) = \frac{Y_{s,k}}{exp(\psi)} \mathbb{I}\{k > t_s^*\} + Y_{s,k} \mathbb{I}\{k \leq t_s^*\}$ where $t_s^*$ is the treatment time for state $s$. Furthermore, we let $g(A_{s,t}) = \mathbb{I}\{A_{s,t} > 0\}$ and $\lambda_{s,t} = p_{s,t}$, the probability of treatment.
Then, we have the following:
\begin{align*}
  0 &= \sum_s \sum_{k=1}^{T + 1} \sum_{t = 0}^{k-1}  \left(\frac{Y_{s,k}}{exp(\psi)} \mathbb{I}\{k > t_s^*\} + Y_{s,k} \mathbb{I}\{k \leq t_s^*\}\right) \mathbb{I}\{\bar{A}_{s,t-1} = \bar{0}\}(\mathbb{I}\{A_{s,t} > 0\} - p_{s,t}) \\
  &= \sum_s \sum_{k=1}^{T + 1} \sum_{t = 0}^{k-1}  Y_{s,k}exp(-\psi) \mathbb{I}\{k > t_s^*\} \mathbb{I}\{\bar{A}_{s,t-1} = \bar{0}\}(\mathbb{I}\{A_{s,t} > 0\} - p_{s,t}) \\
  &+ \sum_s \sum_{k=1}^{T + 1} \sum_{t = 0}^{k-1} Y_{s,k} \mathbb{I}\{k \leq t_s^*\} \mathbb{I}\{\bar{A}_{s,t-1} = \bar{0}\}(\mathbb{I}\{A_{s,t} > 0\} - p_{s,t}) \\
  &\Rightarrow exp(-\psi) \sum_s \sum_{k=1}^{T + 1} \sum_{t = 0}^{k-1}  Y_{s,k} \mathbb{I}\{k > t_s^*\} \mathbb{I}\{\bar{A}_{s,t-1} = \bar{0}\}(\mathbb{I}\{A_{s,t} > 0\} - p_{s,t}) = -\sum_s \sum_{k=1}^{T + 1} \sum_{t = 0}^{k-1} Y_{s,k} \mathbb{I}\{k \leq t_s^*\} \mathbb{I}\{\bar{A}_{s,t-1} = \bar{0}\}(\mathbb{I}\{A_{s,t} > 0\} - p_{s,t}) \\
  &\Rightarrow exp(-\psi) = -\frac{\sum_s \sum_{k=1}^{T + 1} \sum_{t = 0}^{k-1} Y_{s,k} \mathbb{I}\{k \leq t_s^*\} \mathbb{I}\{\bar{A}_{s,t-1} = \bar{0}\}(\mathbb{I}\{A_{s,t} > 0\} - p_{s,t})}{\sum_s \sum_{k=1}^{T + 1} \sum_{t = 0}^{k-1}  Y_{s,k} \mathbb{I}\{k > t_s^*\} \mathbb{I}\{\bar{A}_{s,t-1} = \bar{0}\}(\mathbb{I}\{A_{s,t} > 0\} - p_{s,t})} \\
  &\Rightarrow \psi = - log\left(-\frac{\sum_s \sum_{k=1}^{T + 1} \sum_{t = 0}^{k-1} Y_{s,k} \mathbb{I}\{k \leq t_s^*\} \mathbb{I}\{\bar{A}_{s,t-1} = \bar{0}\}(\mathbb{I}\{A_{s,t} > 0\} - p_{s,t})}{\sum_s \sum_{k=1}^{T + 1} \sum_{t = 0}^{k-1}  Y_{s,k} \mathbb{I}\{k > t_s^*\} \mathbb{I}\{\bar{A}_{s,t-1} = \bar{0}\}(\mathbb{I}\{A_{s,t} > 0\} - p_{s,t})}\right),
\end{align*}
where we model $p_{s,t}$ using the `sum_lag_policies` and `Time_Period_ID` for data points in which $\bar{A}_{s,t-1} = \bar{0}$.
However, if the fraction is positive, then we arrive at an issue since we cannot take the log of a negative.

### With Original Dataset

```{r}
#filter the data to fit the treatment initiation model
dih_dataset_with_past_treatment_equals_0 <- dih_dataset %>%
  # filter data so that t < t_s^* + 1
  filter(Intervention_Redefined < 1)

#fit the treatment initiation model
treatment_initiation_model <- glm(dih_exposure~
                                    sum_lag_policies + 
                                    log_lag_prop_death + 
                                    Time_Period_ID,
                                  data = dih_dataset_with_past_treatment_equals_0,
                                  family = "binomial")

#compute the p_{s,t} and add it into the dih_dataset_with_past_treatment_equals_0
prob_tx <- fitted(treatment_initiation_model)
dih_dataset_with_past_treatment_equals_0$prob_tx <- prob_tx

#compute Y_{s,k} where periods k = 1, ..., T+1 for t = 0, ..., k-1
#to do this, we can use the compute_mimick_potential_outcome() function with gamma_k_t_when_treated as 1
#we also compute an indicator of whether k > t_s^* to indicate whether it is a treated outcome or untreated outcome
data_with_observed_Ysk <- compute_mimick_potential_outcome(dih_dataset, gamma_k_t = 1)

#merge the data with Y_{s,k} and the data with the probability of treatment
observed_Ysk_and_pst <- merge(data_with_observed_Ysk, 
                          dih_dataset_with_past_treatment_equals_0[,c("Time_Period_ID", "State", "prob_tx")],
                          by = c("Time_Period_ID", "State"))

#untreated outcome data to be used for numerator
untreated_outcome_data <- observed_Ysk_and_pst[observed_Ysk_and_pst$treated_outcome_indicator == FALSE,]
numerator <- sum(log(untreated_outcome_data$hkt)*(untreated_outcome_data$dih_exposure - untreated_outcome_data$prob_tx))

#treated outcome data to be used for denominator
treated_outcome_data <- observed_Ysk_and_pst[observed_Ysk_and_pst$treated_outcome_indicator == TRUE,]
denominator <- sum(log(treated_outcome_data$hkt)*(treated_outcome_data$dih_exposure - treated_outcome_data$prob_tx))

-log(-numerator/denominator)

#-0.261831
```

### With Stacked Dataset
```{r}
#compute Y_{s,k} where periods k = 1, ..., T+1 for t =0, ..., k-1
#to do this, we can use the compute_mimick_potential_outcome() function with gamma_k_t_when_treated as 1
#we also compute an indicator of whether k > t_s^* to indicate whether it is a treated outcome or untreated outcome
stacked_data_with_observed_Ysk <- compute_mimick_potential_outcome(dih_dataset, gamma_k_t = 1)

treatment_initiation_model_stacked_data <- glm(dih_exposure~
                                                 sum_lag_policies + 
                                                 lag_prop_deaths +
                                                 Time_Period_ID,
                                               data = stacked_data_with_observed_Ysk,
                                               family = "binomial")

log_treatment_initiation_model_stacked_data <- glm(dih_exposure~
                                                 sum_lag_policies + 
                                                 log_lag_prop_death +
                                                 Time_Period_ID,
                                               data = stacked_data_with_observed_Ysk,
                                               family = "binomial")

#store the p_{s,t}
stacked_data_with_observed_Ysk$prob_tx <- fitted(treatment_initiation_model_stacked_data)

#untreated outcome data to be used for numerator
untreated_outcome_stacked_data <- stacked_data_with_observed_Ysk[stacked_data_with_observed_Ysk$treated_outcome_indicator == FALSE,]
numerator_stacked <- sum(untreated_outcome_stacked_data$hkt*(untreated_outcome_stacked_data$dih_exposure - 
                                                       untreated_outcome_stacked_data$prob_tx))

#treated outcome data to be used for denominator
treated_outcome_stacked_data <- stacked_data_with_observed_Ysk[stacked_data_with_observed_Ysk$treated_outcome_indicator == TRUE,]
denominator_stacked <- sum(treated_outcome_stacked_data$hkt*(treated_outcome_stacked_data$dih_exposure - 
                                                       treated_outcome_stacked_data$prob_tx))

-log(-numerator_stacked/denominator_stacked)

#with lag number of deaths: -0.2242418
#with log lag proportion of deaths: -0.1303734
```

# Two Parameter Model: Binary Treatment
## Mimicking Potential Outcomes
To compute the mimicked potential outcome: $H_{s,k}(t)$ for $k \in \{7-2019, \dotsc, 7-2000 \}$ and $t < k$, we first extract $Y_{s,k}$. We then compute $\gamma_t^k = exp(\psi_1*(a_t - a_{t-1}) + \psi_2*(a_t - a_{t-1})*(k-t_s^*))$. Let $t_s^*$ be the treatment time interval for state $s$. We focus on data points for which $t \leq t_s^*$ and $t<k$. This is because for the treatment initiation model, we include data points for which $t \leq t_s^*$ and we want $t<k$. We let $a_{s,t}$ be a binary variable. For these data points we are interested in, we create the variable `hkt` which is equal to $\frac{Y_{s,k}}{exp(\psi_1 + \psi_2(k-t_s^*))}$ when $k > t_s^*$ (i.e. $Y_{s,k}$ is a treated outcome) and equal to $Y_{s,k}$ when $k \leq t_s^*$ (i.e. $Y_{s,k}$ is an untreated outcome). Lastly, we combine all these datapoints together for each $k$ into a dataset to be returned to use in the treatment initiation model.

```{r}

compute_mimick_potential_outcome_two_parameter_model <- function(dataFrame, psi_1, psi_2){
  #new_df is the dataset we will return, with the new rows appended
  #we initialize it first as the input dataset df
  new_data_frame <- data.frame()
  
  #here, k is the time in which we observe the outcome and t is the time of the treatments
  #so we have k > t
  for(k in max(unique(dataFrame$Time_Period_ID)):2){
    #we first pull out the risk of OD at time k, so Y_k
    outcome_k_data <- dataFrame %>%
      arrange(State) %>%
      filter(Time_Period_ID == k) %>%
      dplyr::select(State, prop_dead, Intervention_First_Date, Time_Period_Start)
    
    #pull the treatment time period for the first treatment date
    tx_time_period_data <- dataFrame %>%
      filter(Time_Period_Start == floor_date(Intervention_First_Date, "6 months")) %>%
      dplyr::select(State, Time_Period_ID)
    
    #rename the Time_Period_ID
    colnames(tx_time_period_data) <- c("State", "t_s")
    
    #merge it with outcome_k_data
    #note: we have all.x = TRUE because we want all the rows in outcome_k_data since the date
    #for Hawaii is set to year 9999, so there are no matches
    outcome_k_data_with_tx_time_period <- merge(outcome_k_data, tx_time_period_data, by = "State",
                                                all.x = TRUE)
    
    #set t_s for Hawaii to be 9999
    outcome_k_data_with_tx_time_period$t_s[outcome_k_data_with_tx_time_period$State == "Hawaii"] <- 9999
    
    #compute k - t_s^*
    outcome_k_data_with_tx_time_period$k_minus_t_s <- k - outcome_k_data_with_tx_time_period$t_s
    
    #compute H_k(t) given psi_1 and psi_2:
    #here, let t^* = treatment time 
    #if k <= t^*, then H_k(t) = Y_k since we havent treated yet, so doesn't affect
    #if t^* < t < k, then H_k(t) = Y_k since a_{t} - a_{t-1} = 0
    #if t <= t^* < k, then H_k(t) = Y_k/exp(psi_1 + psi_2*(k-t_s^*))
    outcome_k_data_with_tx_time_period$hkt <- ifelse(outcome_k_data_with_tx_time_period$k_minus_t_s > 0,
                                 outcome_k_data_with_tx_time_period$prop_dead/
                                   (exp(psi_1 + psi_2*(outcome_k_data_with_tx_time_period$k_minus_t_s))), 
                                 outcome_k_data_with_tx_time_period$prop_dead)
    

    
    #filter the data for which A_{s,t} = 0 and the time interval that contains the treatment time since we only need these data 
    #to predict treatment initiation for the model
    #we also filter so that the t < k
    untreated_and_first_tx_date_data <- dataFrame %>%
      arrange(State, Time_Period_ID) %>%
      #filter for t <= t^* because we use these time periods to predict treatment initiation
      filter(Time_Period_Start <= Intervention_First_Date,
             #filter for t < k
             Time_Period_ID < k)
    
    #merge the filtered dataset with the outcome_k_data which contains the computed H_k(t)
    untreated_and_first_tx_date_data <- merge(untreated_and_first_tx_date_data, 
                                              outcome_k_data_with_tx_time_period[,c("State", "hkt", "k_minus_t_s",
                                                                                 "t_s")], by = "State")
    
    #store k and t
    untreated_and_first_tx_date_data$k <- k
    untreated_and_first_tx_date_data$t <- untreated_and_first_tx_date_data$Time_Period_ID
    untreated_and_first_tx_date_data$date_k <- unique(outcome_k_data$Time_Period_Start)
    
    #compute k - t
    untreated_and_first_tx_date_data$k_minus_t <- untreated_and_first_tx_date_data$k - untreated_and_first_tx_date_data$t
    
    #compute indicator of whether Y_{s,k} is treated outcome
    untreated_and_first_tx_date_data$treated_outcome_indicator <- untreated_and_first_tx_date_data$k_minus_t_s > 0
    
    #we then append the rows to the new_data_frame
    new_data_frame <- rbind(new_data_frame, untreated_and_first_tx_date_data)
  }
  new_data_frame
}



```


## Finding $\psi = (\psi_1, \psi_2)$: $\gamma_t^k = exp(\psi_1 (a_t - a_{t-1}) + \psi_2(a_t - a_{t-1})(k - t_s^*))$
Here, we assume that the treatment effects model is given by the two parameter model:
$$\gamma_t^k = exp(\psi_1*(a_t - a_{t-1}) + \psi_2 *(a_t - a_{t-1})*(k-t_s^*)),$$
where $a_t$ and $a_{t-1}$ are binary variables (for now) indicating whether there have ever been any DIH prosecution media alerts by time $t$ and $t-1$ and $k - t_s^*$ indicates the length of treatment. Further, we have $k > t_s^*$.

We fit a treatment initiation model for the response `dih_exposure` which is a binary variable indicating whether the state was exposed to DIH prosecution in the media, where we use the following as predictors:

* `sum_lag_policies` is the number of other policy measures that have been enacted from time 1 until time $t-1$
* `hkt` is the computed $H_k(t)$
* `hkt*sum_lag_policies` is the interaction between the $H_k(t)$ and the number of policy measures that have been enacted from time 1 until time $t-1$
* `Time_Period_ID` is the linear time effect.

Recall that the `analysis_data_with_hkt` only contains the datapoints for which $t \leq t^*$.
For each value $\psi$, we extract the coefficient of `hkt` from the treatment initiation model, and we find the $\psi$ that leads to a coefficient of zero. 
We also store a vector of `confidence_interval` which stores the values of $\psi$ if the Wald test for the coefficient of `hkt` and `hkt*sum_lag_policies` are not statistically significant at the $alpha = 0.05$ level.


## Grid-Search

```{r}
#################################
psi_grid_params_two_param <- expand.grid(psi_1 = seq(-5,5,by = .5), psi_2 = seq(-5,5,by = .5))
#initialize the vector of coefficients for H(t) in treatment initiation model
pval_grid_two_parameter <- coef_hkt_two_parameter <- rep(NA, nrow(psi_grid_params_two_param))
coef_hkt_sum_policy_two_parameter <- rep(NA, length(psi_grid_params_two_param))
confidence_interval_two_parameter <- data.frame()


for(grid_point in 1:nrow(psi_grid_params_two_param)){
  #statement to print the status of the for loop
  if(grid_point%%10 == 0){print(grid_point)}
  
  #compute H(t) given the dataset and gamma_k_t_when_treated
  analysis_data_with_hkt_two_parameter <- compute_mimick_potential_outcome_two_parameter_model(dih_dataset, 
                                                                                 psi_grid_params_two_param[grid_point,1], 
                                                                                 psi_grid_params_two_param[grid_point,2])
  
  #fit model for treatment initiation
  treatment_initiation_model_two_param <- glm(dih_exposure~ 
                                      sum_lag_policies + 
                                      hkt + 
                                      log_lag_prop_death + 
                                      Time_Period_ID + 
                                      hkt*sum_lag_policies,
                                    data = analysis_data_with_hkt_two_parameter, family = "binomial")
  
  #store the coefficient for H_k(t)
  coef_hkt_two_parameter[grid_point] <- coef(treatment_initiation_model_two_param)["hkt"]
  coef_hkt_sum_policy_two_parameter[grid_point] <- coef(treatment_initiation_model_two_param)["sum_lag_policies:hkt"]
  
  
  #don't do 95% CI yet -- wait until we figure out how to get psi_1, psi_2
  # #conduct the Wald Test for the third coefficient, which is H_k(t) here since the first coefficient is the intercept
  wald_test_results_two_parameter <- wald.test(vcov(treatment_initiation_model_two_param), 
                                               coef(treatment_initiation_model_two_param), Terms = c(3,6))
  # #we then store the p-value and store the psi values if the p-value > 0.05
  pval <- wald_test_results_two_parameter$result$chi2["P"]
  pval_grid_two_parameter[grid_point] <- pval
  if(pval > 0.05){
    confidence_interval_two_parameter <- rbind(confidence_interval_two_parameter, c(psi_grid_params_two_param[grid_point,1], 
                                                        psi_grid_params_two_param[grid_point,2]))
  }
  
}

colnames(confidence_interval_two_parameter) <- c("psi_1", "psi_2")

#stacked data
#psi_1 = -0.078, 95% CI: (-0.759, 0.293)
#psi_2 = 0.002, 95% CI:(-0.012, 0.027)

coef_hkt_two_parameter[221:222]
coef_hkt_sum_policy_two_parameter[221:222]
psi_grid_params_two_param[221:222,]
confidence_interval_two_parameter[1,]
confidence_interval_two_parameter[nrow(confidence_interval_two_parameter),]
plot(pval_grid_two_parameter)
pval_grid_two_parameter[pval_grid_two_parameter>0.03]
psi_grid_params_two_param[which(pval_grid_two_parameter>0.03),]
#psi1 = 0.007, 0.008; 0, 0.0009
```

```{r}
psi_coef_data <- cbind(psi_grid_params_two_param, coef_hkt_two_parameter, coef_hkt_sum_policy_two_parameter)
colnames(psi_coef_data) <- c("psi_1", "psi_2", "coef_hkt", "coef_hkt_sum_policy")
# scatter3D(x = psi_coef_data$psi_1, y= psi_coef_data$psi_2, z = psi_coef_data$coef_hkt,  theta = 130, phi = 30,
#           xlab = "psi 1", ylab = "psi 2", zlab = "Coef of H_k_t")
# scatter3D(x = psi_coef_data$psi_1, y= psi_coef_data$psi_2, z = psi_coef_data$coef_hkt_sum_policy,  theta = 130, phi = 30,
#           xlab = "psi 1", ylab = "psi 2", zlab = "Coef of H_k_t*sum_policy")

#make a table where rows indicate psi_1 and columns indicate psi_2 and values are the coefficient values of H_{s,k}(t)
coef_hkt_mat <- matrix(NA, nrow = length(unique(psi_grid_params_two_param$psi_1)), ncol = length(unique(psi_grid_params_two_param$psi_2)))
rownames(coef_hkt_mat) <- unique(psi_grid_params_two_param$psi_1)
colnames(coef_hkt_mat) <- unique(psi_grid_params_two_param$psi_2)

#make a table where rows indicate psi_1 and columns indicate psi_2 and values are the coefficient values of H_{s,k}(t)*sum_policy
coef_hkt_mat_sum_policy <- matrix(NA, nrow = length(unique(psi_grid_params_two_param$psi_1)), 
                                  ncol = length(unique(psi_grid_params_two_param$psi_2)))
rownames(coef_hkt_mat_sum_policy) <- unique(psi_grid_params_two_param$psi_1)
colnames(coef_hkt_mat_sum_policy) <- unique(psi_grid_params_two_param$psi_2)

for(grid_point in 1:nrow(psi_coef_data)){
  coef_hkt_mat[as.character(psi_coef_data$psi_1[grid_point]), as.character(psi_coef_data$psi_2[grid_point])] <-
    psi_coef_data$coef_hkt[grid_point]
  coef_hkt_mat_sum_policy[as.character(psi_coef_data$psi_1[grid_point]), as.character(psi_coef_data$psi_2[grid_point])] <-
    psi_coef_data$coef_hkt_sum_policy[grid_point]
}
coef_hkt_mat
coef_hkt_mat_sum_policy

```



## Solving for $\psi_1$

In the two-paramter model, we can't solve for both $psi_1$ and $psi_2$. However, we can solve for $psi_1$ as a function of $psi_2$.
We showed that:
$$E\left(\sum_s \sum_{k=1}^{T + 1} \sum_{t = 0}^{k-1} \vec{q}{_t}^{k}(\bar{X}_{s,t}, \bar{A}_{s,t-1}) H_{s,k}(t) \mathbb{I}\{\bar{A}_{s,t-1} = \bar{0}\}({g(A}_{s,t}) - \lambda_{s,t})\right) = 0.$$
We let $\vec{q}{_t}^{k}(\bar{X}_{s,t}, \bar{A}_{s,t-1}) = 1$ and $H_{s,k}(t) = \frac{Y_{s,k}}{exp(\psi_1 + \psi_2*(k - t_s^*))} \mathbb{I}\{k > t_s^*\} + Y_{s,k} \mathbb{I}\{k \leq t_s^*\}$ where $t_s^*$ is the treatment time for state $s$. Furthermore, we let $g(A_{s,t}) = \mathbb{I}\{A_{s,t} > 0\}$ and $\lambda_{s,t} = p_{s,t}$, the probability of treatment.
Then, we have the following:
\begin{align*}
  0 &= \sum_s \sum_{k=1}^{T + 1} \sum_{t = 0}^{k-1}  \left(\frac{Y_{s,k}}{exp(\psi_1 + \psi_2*(k - t_s^*))} \mathbb{I}\{k > t_s^*\} + Y_{s,k} \mathbb{I}\{k \leq t_s^*\}\right) \mathbb{I}\{\bar{A}_{s,t-1} = \bar{0}\}(\mathbb{I}\{A_{s,t} > 0\} - p_{s,t}) \\
  &= \sum_s \sum_{k=1}^{T + 1} \sum_{t = 0}^{k-1}  Y_{s,k}exp(-\psi_1 - \psi_2*(k - t_s^*)) \mathbb{I}\{k > t_s^*\} \mathbb{I}\{\bar{A}_{s,t-1} = \bar{0}\}(\mathbb{I}\{A_{s,t} > 0\} - p_{s,t}) \\
  &+ \sum_s \sum_{k=1}^{T + 1} \sum_{t = 0}^{k-1} Y_{s,k} \mathbb{I}\{k \leq t_s^*\} \mathbb{I}\{\bar{A}_{s,t-1} = \bar{0}\}(\mathbb{I}\{A_{s,t} > 0\} - p_{s,t}) \\
  &\Rightarrow exp(-\psi_1) \sum_s \sum_{k=1}^{T + 1} \sum_{t = 0}^{k-1}  Y_{s,k}exp(-\psi_2*(k - t_s^*)) \mathbb{I}\{k > t_s^*\} \mathbb{I}\{\bar{A}_{s,t-1} = \bar{0}\}(\mathbb{I}\{A_{s,t} > 0\} - p_{s,t}) = -\sum_s \sum_{k=1}^{T + 1} \sum_{t = 0}^{k-1} Y_{s,k} \mathbb{I}\{k \leq t_s^*\} \mathbb{I}\{\bar{A}_{s,t-1} = \bar{0}\}(\mathbb{I}\{A_{s,t} > 0\} - p_{s,t}) \\
  &\Rightarrow exp(-\psi_1) = -\frac{\sum_s \sum_{k=1}^{T + 1} \sum_{t = 0}^{k-1} Y_{s,k}exp(-\psi_2*(k - t_s^*)) \mathbb{I}\{k \leq t_s^*\} \mathbb{I}\{\bar{A}_{s,t-1} = \bar{0}\}(\mathbb{I}\{A_{s,t} > 0\} - p_{s,t})}{\sum_s \sum_{k=1}^{T + 1} \sum_{t = 0}^{k-1}  Y_{s,k} \mathbb{I}\{k > t_s^*\} \mathbb{I}\{\bar{A}_{s,t-1} = \bar{0}\}(\mathbb{I}\{A_{s,t} > 0\} - p_{s,t})} \\
  &\Rightarrow \psi_1 = - log\left(-\frac{\sum_s \sum_{k=1}^{T + 1} \sum_{t = 0}^{k-1} Y_{s,k} exp(-\psi_2*(k - t_s^*)) \mathbb{I}\{k \leq t_s^*\} \mathbb{I}\{\bar{A}_{s,t-1} = \bar{0}\}(\mathbb{I}\{A_{s,t} > 0\} - p_{s,t})}{\sum_s \sum_{k=1}^{T + 1} \sum_{t = 0}^{k-1}  Y_{s,k} \mathbb{I}\{k > t_s^*\} \mathbb{I}\{\bar{A}_{s,t-1} = \bar{0}\}(\mathbb{I}\{A_{s,t} > 0\} - p_{s,t})}\right),
\end{align*}

Hence, we first fit a logistic regression model to predict $p_{s,t}$. Then, we use grid search to find a value a $\psi_2$ (and therefore, a value for $\psi_1$) such that the coefficients of `hkt` and `hkt:sum_lag_policies` are both zero.

```{r}
#solving for psi_1 from unbiased estimating equations, we can write psi_1 as a function of psi_2
compute_psi_1 <- function(psi_2, untreated_data, treated_data){
  #compute psi_1
  numerator <- sum(untreated_data$hkt*(untreated_data$dih_exposure - untreated_data$prob_tx))
  denominator <- sum(treated_data$hkt*exp(-psi_2*treated_data$k_minus_t_s)*(treated_data$dih_exposure - treated_data$prob_tx))
  
  psi_1 <- -log(-numerator/denominator)
  return(psi_1)
  
}
```

### Stacked Data to Compute Intervention Probability
```{r}
#stacked data
#only need to run this once, so don't need to put it into the psi_1 computation function
#first extract Y_{s,k} for the appropriate k = 40, ..., 2 for each t = 0, ..., k-1
stacked_observed_Ysk <- compute_mimick_potential_outcome(dih_dataset, gamma_k_t = 1)

#predict treatment initiation
treatment_initiation_model_stacked <- glm(dih_exposure~ 
                                            sum_lag_policies + 
                                            lag_deaths +
                                            Time_Period_ID,
                                          data = stacked_observed_Ysk,
                                          family = "binomial")
stacked_observed_Ysk$prob_tx <- fitted(treatment_initiation_model_stacked)

#filter to datapoints where k > t_s$* and where k <= t_s^*
stacked_untreated_data <- stacked_observed_Ysk[stacked_observed_Ysk$treated_outcome_indicator == FALSE,]
stacked_treated_data <- stacked_observed_Ysk[stacked_observed_Ysk$treated_outcome_indicator == TRUE,]

psi_grid_params_psi_2_stacked <- seq(-.02, .03, length.out = 500)
psi_grid_params_psi_1_stacked <- sapply(psi_grid_params_psi_2_stacked, function(psi_2){compute_psi_1(psi_2, 
                                                                                             stacked_untreated_data, 
                                                                                             stacked_treated_data)})

#################################

#initialize the vector of coefficients for H(t) in treatment initiation model
coef_hkt <- rep(NA, length(psi_grid_params_psi_2_stacked))
coef_hkt_sum_policy <- rep(NA, length(psi_grid_params_psi_2_stacked))
confidence_interval <- data.frame()


for(grid_point in 1:length(psi_grid_params_psi_2_stacked)){
  #statement to print the status of the for loop
  # if(grid_point%%10 == 0){print(grid_point)}
  
  #some psi_1 is NaN so we don't compute for those
  if(!is.nan(psi_grid_params_psi_1_stacked)){
    #compute H(t) given the dataset and gamma_k_t_when_treated
    analysis_data_with_hkt <- compute_mimick_potential_outcome_two_parameter_model(dih_dataset, 
                                                                                   psi_grid_params_psi_1_stacked[grid_point], 
                                                                                   psi_grid_params_psi_2_stacked[grid_point])
    
    #fit model for treatment initiation
    treatment_initiation_model <- glm(dih_exposure~ 
                                        sum_lag_policies + 
                                        hkt + 
                                        Time_Period_ID + 
                                        hkt*sum_lag_policies,
                                      data = analysis_data_with_hkt, family = "binomial")
    
    #store the coefficient for H_k(t)
    coef_hkt[grid_point] <- coef(treatment_initiation_model)["hkt"]
    coef_hkt_sum_policy[grid_point] <- coef(treatment_initiation_model)["sum_lag_policies:hkt"]
    
    
    #don't do 95% CI yet -- wait until we figure out how to get psi_1, psi_2
    # #conduct the Wald Test for the third coefficient, which is H_k(t) here since the first coefficient is the intercept
    wald_test_results <- wald.test(vcov(treatment_initiation_model), coef(treatment_initiation_model), Terms = c(3,5))
    # #we then store the p-value and store the psi values if the p-value > 0.05
    pval <- wald_test_results$result$chi2["P"]
    if(pval > 0.05){
      confidence_interval <- rbind(confidence_interval, c(psi_grid_params_psi_1_stacked[grid_point], 
                                                          psi_grid_params_psi_2_stacked[grid_point]))
    }
  }
}

colnames(confidence_interval) <- c("psi_1", "psi_2")

#stacked data
#psi_1 = -0.078, 95% CI: (-0.759, 0.293)
#psi_2 = 0.002, 95% CI:(-0.012, 0.027)

coef_hkt[221:222]
coef_hkt_sum_policy[221:222]
psi_grid_params_psi_1_stacked[221:222]
psi_grid_params_psi_2_stacked[221:222]
confidence_interval[1,]
confidence_interval[nrow(confidence_interval),]

```

The $\psi_1$ and $\psi_2$ that solves the unbiased estimating equations are $\psi_1 = -0.078$ with 95% CI = (-0.759, 0.293) and $\psi_2 = 0.002$ with 95% CI = (-0.012, 0.027).

We use the values of $\psi_1$ and $\psi_2$ to check whether the unbiased estimating equations are equal to 0.

### Check Unbiased Estimating Equation
We first check the unbiased estimating equation where $H_{s,k}(t)$ is added to the treatment initiation model.

```{r}
psi_1_sol <- -0.07830036
psi_2_sol <- 0.002093131

sum(stacked_untreated_data$hkt*(stacked_untreated_data$dih_exposure - stacked_untreated_data$prob_tx)) + 
  sum(stacked_treated_data$hkt/(exp(psi_1_sol + psi_2_sol*(stacked_treated_data$k_minus_t_s)))*(
    stacked_treated_data$dih_exposure - stacked_treated_data$prob_tx
  ))

```

We also check the unbiased estimating equation where $H_{s,k}(t) \times \text{sum policies}$ is added to the treatment initiation model.

```{r}
psi_1_sol <- -0.07830036
psi_2_sol <- 0.002093131

sum(stacked_untreated_data$hkt*stacked_untreated_data$sum_policies*
      (stacked_untreated_data$dih_exposure - stacked_untreated_data$prob_tx)) + 
  sum(stacked_treated_data$hkt/(exp(psi_1_sol + psi_2_sol*(stacked_treated_data$k_minus_t_s)))*
        stacked_treated_data$sum_policies*(
    stacked_treated_data$dih_exposure - stacked_treated_data$prob_tx
  ))

```

### Plot the $\psi_1$ and $\psi_2$
```{r}
total_psi_effect <- data.frame(time = 0:28,
                               sum_psi = psi_1_sol + psi_2_sol*c(0:28),
                               sum_psi_lb = -0.759 -0.012*c(0:28),
                               sum_psi_ub = 0.293 + 0.027*c(0:28))

ggplot(total_psi_effect, aes(x = time)) + 
  geom_line(aes(y = sum_psi, linetype = "Estimate")) + 
  geom_line(aes(y = sum_psi_lb, linetype = "95% CI")) + 
  geom_line(aes(y = sum_psi_ub, linetype = "95% CI"))+ 
  scale_linetype_manual(values = c("dashed", "solid")) + 
  labs(linetype = "",
       x = expression(k - t[s]^`*`),
       y = expression(psi[1] + psi[2](k-t[s]^`*`)),
       title = expression(psi[1] + psi[2](k-t[s]^`*`))) + 
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(), axis.line = element_line(colour = "black"),
        legend.position = "bottom") + 
  geom_hline(aes(yintercept = 0), color = "grey", linetype = "dotted")
```





# Count Model
```{r}
#create a plot for each state to see how many prosecution media alerts there are per 6 month period
#read in the prosecution media alert data
prosecution_data<-read.csv("./Data/dih_prosecutions_9_6_21.csv")

#data cleaning
prosecution_data<-prosecution_data %>% 
  mutate(Date = as.Date(Date.charged, "%m/%d/%Y")) %>%
  mutate(State = ifelse(State.Filed == "pennsylvania", "Pennsylvania", State.Filed),
         State = ifelse(State.Filed == "Virginia ", "Virginia", State)) %>%
  mutate(deceased_age = ifelse(!is.na(as.numeric(Deceased.s.Age)), as.numeric(Deceased.s.Age), 9999)) %>%
  filter(!is.na(Date), 
         State.Filed != "No Info", 
         State.Filed != "No info", 
         State.Filed != "No Info ",
         deceased_age >= 18,
         State != "" ) %>%
  mutate(deceased_age = ifelse(deceased_age == 9999, NA, deceased_age))

#clean up the data by looking at the link to the article
prosecution_data$Date[prosecution_data$Date == "2026-08-01"] <- as.Date("2016-02-15", "%Y-%m-%d")

#change the states into Character instead of factor
prosecution_data$State<-as.character(prosecution_data$State)
#see how many prosecution data points there are for each state
table(prosecution_data$State)

#there are some repeated cases depending on victim so extract distinct cases
prosecution_data_unique <- prosecution_data %>%
  group_by(State) %>%
  distinct(Accused.Name, Date, .keep_all = T)
table(prosecution_data_unique$State)

#change date charged into Date object
prosecution_data_unique$Date<-mdy(prosecution_data_unique$Date.charged)

#group the data into six month periods
prosecution_data_unique<-prosecution_data_unique %>% 
  mutate(six_month_pd = lubridate::floor_date(Date , "6 months" ))

prosecution_grouped <- prosecution_data_unique %>% 
  #filter to dates after 2000 and dates before 2020
  filter(year(six_month_pd) >= 2000 & year(six_month_pd) <= 2019) %>%
  group_by(State, six_month_pd) %>% 
  #for each state, for each six month period, count the number of DIH prosecutions
  summarise(num_dih = n())

dih_dataset_with_num_dih <- merge(dih_dataset, prosecution_grouped,
                                  by.x = c("State", "Time_Period_Start"),
                                  by.y = c("State", "six_month_pd"),
                                  all.x = TRUE)
#impute a 0 for the NAs
dih_dataset_with_num_dih$num_dih[is.na(dih_dataset_with_num_dih$num_dih)] <- 0

#create a column for the lag number of DIH prosecutions reported by media
dih_dataset_with_num_dih <- dih_dataset_with_num_dih %>%
  arrange(State, Time_Period_ID) %>%
  group_by(State) %>%
  mutate(lag_num_dih = lag(num_dih)) 

#assume that prior to the analysis period, there were no DIH prosecutions reported by media
dih_dataset_with_num_dih$lag_num_dih[dih_dataset_with_num_dih$Time_Period_ID == 1] <- 0

#compute the diff in number of DIH prosecutions
dih_dataset_with_num_dih$diff_num_dih <- dih_dataset_with_num_dih$num_dih - dih_dataset_with_num_dih$lag_num_dih
```

# One Parameter Model: Count Treatment Variable
## Mimicking Potential Outcomes
To compute the mimicked potential outcome: $H_{s,k}(t)$ for $k \in \{7-2019, \dotsc, 7-2000 \}$ and $t < k$, we first extract $Y_{s,k}$. We then compute $\gamma_t^k = exp(\psi*(a_{s,t} - a_{s,t-1}))$. Let $t_s^*$ be the treatment time interval for state $s$. We focus on data points for which $t \leq t_s^*$ and $t<k$. This is because for the treatment initiation model, we include data points for which $t \leq t_s^*$ and we want $t<k$. We let $a_{s,t}$ be the number of DIH prosecutions. For these data points we are interested in, we create the variable `hkt` which is equal to $\frac{Y_{s,k}}{exp(\psi*(a_{s,t} - a_{s,t-1}))}$ when $k > t_s^*$ (i.e. $Y_{s,k}$ is a treated outcome) and equal to $Y_{s,k}$ when $k \leq t_s^*$ (i.e. $Y_{s,k}$ is an untreated outcome). Lastly, we combine all these datapoints together for each $k$ into a dataset to be returned to use in the treatment initiation model.

```{r}
compute_mimick_potential_outcome_count <- function(dataFrame, psi){
  #new_df is the dataset we will return, with the new rows appended
  #we initialize it first as the input dataset df
  new_data_frame <- data.frame()
  
  #here, k is the time in which we observe the outcome and t is the time of the treatments
  #so we have k > t
  for(k in max(unique(dataFrame$Time_Period_ID)):2){
    #we first pull out the risk of OD at time k, so Y_k
    outcome_k_data <- dataFrame %>%
      arrange(State) %>%
      filter(Time_Period_ID == k) %>%
      dplyr::select(State, log_prop_dead, Intervention_First_Date, Time_Period_Start) %>%
      rename(ysk = log_prop_dead)
    
    #pull the treatment time period for the first treatment date
    tx_time_period_data <- dataFrame %>%
      filter(Time_Period_Start == floor_date(Intervention_First_Date, "6 months")) %>%
      dplyr::select(State, Time_Period_ID)
    
    #rename the Time_Period_ID
    colnames(tx_time_period_data) <- c("State", "t_s")
    
    
    #merge it with outcome_k_data
    #note: we have all.x = TRUE because we want all the rows in outcome_k_data since the date
    #for Hawaii is set to year 9999, so there are no matches
    outcome_k_data_with_tx_time_period <- merge(outcome_k_data, tx_time_period_data, by = "State",
                                                all.x = TRUE)
    
    #set t_s for Hawaii to be 9999
    outcome_k_data_with_tx_time_period$t_s[outcome_k_data_with_tx_time_period$State == "Hawaii"] <- 9999
    
    #compute k - t_s^*
    outcome_k_data_with_tx_time_period$k_minus_t_s <- k - outcome_k_data_with_tx_time_period$t_s
    
    #initialize the value to be used to compute hkt for next time period
    hkt_helper_for_next_period <- outcome_k_data_with_tx_time_period[,c("ysk", "State")]
    colnames(hkt_helper_for_next_period) <- c("hkt_plus_1", "State")
    
    #now loop through t < k
    for(t in (k-1):1){
      #filter data to include only those with time t < k
      data_at_t <- dataFrame %>%
        filter(Time_Period_ID == t) 
      
      data_at_t <- merge(data_at_t, outcome_k_data_with_tx_time_period[,c("ysk", "t_s", "k_minus_t_s", "State")],
                             by = "State")
      
      #add hkt_plus_1 to data framt at time t
      data_at_t <- merge(data_at_t, hkt_helper_for_next_period, by = "State")
      
      #compute H_k(t) given gamma_k_t:
      #here, let t^* = treatment time 
      #if k <= t^*, then H_k(t) = Y_k since we havent treated yet, so doesn't affect
      #if t^* < t < k, then H_k(t) = Y_k since a_{t} - a_{t-1} = 0
      #if t <= t^* < k, then H_k(t) = Y_k/gamma_k_t
      data_at_t$hkt <- ifelse(data_at_t$k_minus_t_s > 0,
                              data_at_t$hkt_plus_1/exp(psi*(data_at_t$diff_num_dih)), 
                              data_at_t$hkt_plus_1)
      
      #compute values that may be useful
      #add k and t to the dataset and the date of k
      data_at_t$k <- k
      data_at_t$date_k <- unique(outcome_k_data_with_tx_time_period$Time_Period_Start)
      data_at_t$t <- data_at_t$Time_Period_ID
      
      #compute k - t
      data_at_t$k_minus_t <- k - data_at_t$t
      #compute indicator of whether Y_{s,k} is treated outcome
      data_at_t$treated_outcome_indicator <- data_at_t$k_minus_t_s > 0
      
      #we then append the rows to the new_data_frame
      new_data_frame <- rbind(new_data_frame, data_at_t)
      
      #the value to be used to compute hkt for next time period
      hkt_helper_for_next_period <- data_at_t[,c("hkt", "State")]
      colnames(hkt_helper_for_next_period) <- c("hkt_plus_1", "State")
    }

  }
  new_data_frame
}

# compute_mimick_potential_outcome_count <- function(dataFrame, psi){
#   #new_df is the dataset we will return, with the new rows appended
#   #we initialize it first as the input dataset df
#   new_data_frame <- data.frame()
#   
#   #here, k is the time in which we observe the outcome and t is the time of the treatments
#   #so we have k > t
#   for(k in max(unique(dataFrame$Time_Period_ID)):2){
#     #we first pull out the risk of OD at time k, so Y_k
#     outcome_k_data <- dataFrame %>%
#       arrange(State) %>%
#       filter(Time_Period_ID == k) %>%
#       dplyr::select(State, log_prop_dead, Intervention_First_Date, Time_Period_Start) %>%
#       rename(ysk = log_prop_dead)
#     
#     #pull the treatment time period for the first treatment date
#     tx_time_period_data <- dataFrame %>%
#       filter(Time_Period_Start == floor_date(Intervention_First_Date, "6 months")) %>%
#       dplyr::select(State, Time_Period_ID)
#     
#     #rename the Time_Period_ID
#     colnames(tx_time_period_data) <- c("State", "t_s")
#     
#     
#     #merge it with outcome_k_data
#     #note: we have all.x = TRUE because we want all the rows in outcome_k_data since the date
#     #for Hawaii is set to year 9999, so there are no matches
#     outcome_k_data_with_tx_time_period <- merge(outcome_k_data, tx_time_period_data, by = "State",
#                                                 all.x = TRUE)
#     
#     #set t_s for Hawaii to be 9999
#     outcome_k_data_with_tx_time_period$t_s[outcome_k_data_with_tx_time_period$State == "Hawaii"] <- 9999
#     
#     #compute k - t_s^*
#     outcome_k_data_with_tx_time_period$k_minus_t_s <- k - outcome_k_data_with_tx_time_period$t_s
#     
#     #filter data to include only those with time t < k
#     data_before_k <- dataFrame %>%
#       filter(Time_Period_ID < k) 
#     
#     data_before_k <- merge(data_before_k, outcome_k_data_with_tx_time_period[,c("ysk", "t_s", "k_minus_t_s", "State")],
#                            by = "State")
#     
#     
#     #compute H_k(t) given gamma_k_t:
#     #here, let t^* = treatment time 
#     #if k <= t^*, then H_k(t) = Y_k since we havent treated yet, so doesn't affect
#     #if t^* < t < k, then H_k(t) = Y_k since a_{t} - a_{t-1} = 0
#     #if t <= t^* < k, then H_k(t) = Y_k/gamma_k_t
#     data_before_k$hkt <- ifelse(data_before_k$k_minus_t_s > 0,
#                                 data_before_k$ysk/exp(psi*(data_before_k$diff_num_dih)), 
#                                 data_before_k$ysk)
#     
#     
#     #compute values that may be useful
#     #add k and t to the dataset and the date of k
#     data_before_k$k <- k
#     data_before_k$date_k <- unique(outcome_k_data_with_tx_time_period$Time_Period_Start)
#     data_before_k$t <- data_before_k$Time_Period_ID
#     
#     
#     #compute k - t
#     data_before_k$k_minus_t <- k - data_before_k$t
#     #compute indicator of whether Y_{s,k} is treated outcome
#     data_before_k$treated_outcome_indicator <- data_before_k$k_minus_t_s > 0
#     
#     #we then append the rows to the new_data_frame
#     new_data_frame <- rbind(new_data_frame, data_before_k)
#   }
#   new_data_frame
# }



```

## Finding $\psi$: $\gamma_t^k = exp(\psi (a_t - a_{t-1}))$
Here, we assume that the treatment effects model is given by the one parameter model:
$$\gamma_t^k = exp(\psi*(a_t - a_{t-1})),$$
where $a_t$ and $a_{t-1}$ are count variables indicating whether there have ever been any DIH prosecution media alerts by time $t$ and $t-1$. Further, we have $k > t_s^*$.

We fit a treatment initiation model for the response `num_dih` which is a count variable indicating whether the state was exposed to DIH prosecution in the media, where we use the following as predictors:

* `sum_lag_policies` is the number of other policy measures that have been enacted from time 1 until time $t-1$
* `hkt` is the computed $H_k(t)$
* `log_lag_prop_death` is the log of the lagged proportion of drug overdose deaths
* `Time_Period_ID` is the linear time effect.

For each value $\psi$, we extract the coefficient of `hkt` from the treatment initiation model, and we find the $\psi$ that leads to a coefficient of zero. 
We also store a vector of `confidence_interval` which stores the values of $\psi$ if the Wald test for the coefficient of `hkt` is not statistically significant at the $alpha = 0.05$ level.

```{r}
#create a vector of 100 psi
# psi_grid_params <- seq(-0.1012847, -0.1012846, length.out = 100)
# psi_grid_params <- seq(-.2, .1, by = 0.001)
psi_grid_params_count <- seq(-1, 1, y = 0.5)
 #initialize the vector of coefficients for H(t) in treatment initiation model
coef_hkt_count <- rep(NA, length(psi_grid_params_count))
confidence_interval_count <- c()
for(grid_point in 1:length(psi_grid_params_count)){
  #statement to print the status of the for loop
  if(grid_point%%10 == 0){print(grid_point)}

  #compute H(t) given the dataset and gamma_k_t
  analysis_data_with_hkt_count <- compute_mimick_potential_outcome_count(dih_dataset_with_num_dih, psi_grid_params_count[grid_point])
 
  #fit model for treatment initiation
  treatment_initiation_model_count <- glm(num_dih~ 
                       sum_lag_policies + 
                       hkt +
                       log_lag_prop_death +   
                       Time_Period_ID,
                     data = analysis_data_with_hkt_count, family = "poisson")
  
  #store the coefficient for H_k(t)
  coef_hkt_count[grid_point] <- coef(treatment_initiation_model_count)["hkt"]
  
  #conduct the Wald Test for the third coefficient, which is H_k(t) here since the first coefficient is the intercept
  wald_test_results_count <- wald.test(vcov(treatment_initiation_model_count), coef(treatment_initiation_model_count), 3)
  #we then store the p-value and store the psi values if the p-value > 0.05
  pval_count <- wald_test_results_count$result$chi2["P"]
  if(pval_count > 0.05){
    confidence_interval_count <- rbind(confidence_interval_count, psi_grid_params_count[grid_point])
  }
}

coef_hkt_count[89:90]
psi_grid_params_count[89:90]
as.vector(confidence_interval_count)

#0.14
#CI: (-.0121, -0.0102)
```

When we included the past number of drug overdose deaths as the log of probability of drug overdose deaths into the treatment model, the $\psi$ that produced an $\alpha(\psi)$, where $\alpha(\psi)$ is the coefficient of $H_k(t)$ in the treatment model, that is closest to 0 is -0.011. The 95% Confidence Interval is (-.0121, -0.0102).


## Checking Grid-Search
Note we cannot just solve for $\psi$ from the unbiased estimating equations
We showed that 
$$E\left(\sum_s \sum_{k=1}^{T + 1} \sum_{t = 0}^{k-1} \vec{q}{_t}^{k}(\bar{X}_{s,t}, \bar{A}_{s,t-1}) H_{s,k}(t) \mathbb{I}\{\bar{A}_{s,t-1} = \bar{0}\}({g(A}_{s,t}) - \lambda_{s,t})\right) = 0.$$
We let $\vec{q}{_t}^{k}(\bar{X}_{s,t}, \bar{A}_{s,t-1}) = 1$ and $H_{s,k}(t) = \frac{\log Y_{s,k}}{exp(\psi*(a_{t} - a_{t-1}))} \mathbb{I}\{k > t_s^*\} + \log Y_{s,k} \mathbb{I}\{k \leq t_s^*\}$ where $Y_{s,k}$ is the probability of drug overdose death and $t_s^*$ is the treatment time for state $s$. Furthermore, we let $g(A_{s,t}) = A_{s,t}$ and $\lambda_{s,t} = \mu_{s,t}$, the mean number of DIH prosecutions.
Then, we have the following:
\begin{align*}
  0 &= \sum_s \sum_{k=1}^{T + 1} \sum_{t = 0}^{k-1}  \left(\frac{\log Y_{s,k}}{exp(\psi*(a_{t} - a_{t-1}))} \mathbb{I}\{k > t_s^*\} + \log Y_{s,k} \mathbb{I}\{k \leq t_s^*\}\right) \mathbb{I}\{\bar{A}_{s,t-1} = \bar{a}_{t-1}\}(A_{s,t} - \lambda_{s,t}) \\
  &= \sum_s \sum_{k=1}^{T + 1} \sum_{t = 0}^{k-1}  \log Y_{s,k}exp(-\psi*(a_{t} - a_{t-1}))\mathbb{I}\{k > t_s^*\} \mathbb{I}\{\bar{A}_{s,t-1} = \bar{a}_{t-1}\}(A_{s,t}  - \lambda_{s,t}) \\
  &+ \sum_s \sum_{k=1}^{T + 1} \sum_{t = 0}^{k-1} \log Y_{s,k} \mathbb{I}\{k \leq t_s^*\} \mathbb{I}\{\bar{A}_{s,t-1} = \bar{a}_{t-1}\}(A_{s,t} - \lambda_{s,t}),
\end{align*}
and we cannot isolate the $\psi$.
However, we can check the validity of our $\psi$ estimate using the unbiased estimating equation. 

```{r}
#compute Y_{s,k} where periods k = 1, ..., T+1 for t =0, ..., k-1
#to do this, we can use the compute_mimick_potential_outcome() function with gamma_k_t_when_treated as 1
#we also compute an indicator of whether k > t_s^* to indicate whether it is a treated outcome or untreated outcome
stacked_data_with_observed_Ysk_count <- compute_mimick_potential_outcome_count(dih_dataset_with_num_dih, psi = 0)

#psi from the grid search
psi_from_grid_search <- -0.011

treatment_initiation_model_stacked_data_count <- glm(num_dih~
                                                 sum_lag_policies + 
                                                 log_lag_prop_death +
                                                 Time_Period_ID,
                                               data = stacked_data_with_observed_Ysk_count,
                                               family = "poisson")

#store the p_{s,t}
stacked_data_with_observed_Ysk_count$est_mean_num_dih <- fitted(treatment_initiation_model_stacked_data_count)

#untreated outcome data to be used for numerator
untreated_outcome_stacked_data_count <- stacked_data_with_observed_Ysk_count[
  stacked_data_with_observed_Ysk_count$treated_outcome_indicator == FALSE,]
untreated_term_count<- sum(untreated_outcome_stacked_data$hkt*(untreated_outcome_stacked_data_count$num_dih - 
                                                       untreated_outcome_stacked_data_count$est_mean_num_dih))

#treated outcome data to be used for denominator
treated_outcome_stacked_data_count <- stacked_data_with_observed_Ysk_count[
  stacked_data_with_observed_Ysk_count$treated_outcome_indicator == TRUE,]
treated_term_count <- sum(treated_outcome_stacked_data_count$hkt*
                            (exp(-psi_from_grid_search*(treated_outcome_stacked_data_count$diff_num_dih)))*
                            (treated_outcome_stacked_data_count$num_dih - 
                                                       treated_outcome_stacked_data_count$est_mean_num_dih))

untreated_term_count + treated_term_count

#with lag number of deaths: -0.2242418
#with log lag proportion of deaths: -0.1303734
```



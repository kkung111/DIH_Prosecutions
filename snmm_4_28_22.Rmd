---
title: "Coarse SNNM: DIH Prosecutions"
author: "Kelly Kung"
date: "4/12/2022"
output: 
  html_document:
    toc: true
    toc_float: true
    number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_knit$set(echo = TRUE, root.dir = "~/OneDrive - Boston University/Research-Lok")
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
```

# Set Up
## R Code 
```{r}
#packages we need for this code file
library(ggplot2)
library(mgcv)
library(lubridate)
library(zoo)
library(tidyverse)
library(dplyr)
library(aod)

``` 

## Data 
```{r}
#read in data
main_analysis_data<-read.csv("./Data/full_data_set_11_29_21_unintentional.csv")

################################## set up data set ################################
#add the intervention dates and time period data
main_analysis_data$Intervention_First_Date<-as.Date(main_analysis_data$Intervention_First_Date)
main_analysis_data$Time_Period_Start<-as.Date(main_analysis_data$Time_Period_Start)
names(main_analysis_data)[which(colnames(main_analysis_data) == "sum_deaths")] <- "imputed_deaths"
main_analysis_data$dih_exposure <- as.numeric(main_analysis_data$Intervention_Redefined > 0)
#compute the risk of overdose death
main_analysis_data$prop_dead <- main_analysis_data$imputed_deaths/main_analysis_data$population

```

# Model for Treatment Effect
## Create Dataset
```{r}

#create sum of policies already enacted for treatment initiation
#create a new dataset dih_dataset for which we can make changes to
dih_dataset <- main_analysis_data
#we first create lag variables for the policies so that we know that by time t, whether the policy has been enacted
#note that we don't count what happened at time t
dih_dataset <- dih_dataset %>%
  #make sure that the data is ordered according to first state and then time period
  arrange(State, Time_Period_ID) %>%
  #group by state so that when we lag, we only lag within the state
  group_by(State) %>%
  mutate(lag_tx = lag(dih_exposure),
         lag_naloxone_pharm_yes = lag(Naloxone_Pharmacy_Yes_Redefined),
         lag_naloxone_pharm_no = lag(Naloxone_Pharmacy_No_Redefined),
         lag_medical_marijuana = lag(Medical_Marijuana_Redefined),
         lag_rec_marijuana = lag(Recreational_Marijuana_Redefined),
         lag_gsl = lag(GSL_Redefined),
         lag_pdmp = lag(PDMP_Redefined),
         lag_medicaid = lag(Medicaid_Expansion_Redefined),
         lag_intervention = lag(Intervention_Redefined),
         lag_prop_deaths = lag(imputed_deaths/population),
         lag_deaths = lag(imputed_deaths)) 

#we want to impute the lag number of deaths with the deaths from 1999 -- we can obtain from previous data cleaning work
drug_od_data <- read.csv("./Data/od_data_interpolated_unintentional_1999_2019_age_18_and_up_11_29_21.csv")
#group data by 6 months
drug_od_data_grouped <- drug_od_data %>%
  mutate(Date = as.Date(Date)) %>%
  mutate(Time_Period_Start = lubridate::floor_date(Date , "6 months" ))

#population for 1999 - obtained from NBER https://data.nber.org/data/census-intercensal-population/
pop_data <- read.csv("./Data/pop7099s.csv")
pop_1999 <- pop_data %>%
  filter(year == 1999,
         age >= 18) %>%
  group_by(state) %>%
  summarise(total_pop = sum(pop))

drug_od_data_grouped_1999<- drug_od_data_grouped %>% 
  filter(year(Time_Period_Start) == 1999) %>%
  group_by(State, Time_Period_Start) %>%
  summarise(sum_deaths = sum(interp_vals, na.rm = TRUE))

drug_od_w_pop <- merge(drug_od_data_grouped_1999, pop_1999,
                       by.x = "State", by.y = "state")

#pull out the interpolated deaths for July - December 1999
od_july_1999 <- drug_od_w_pop %>%
  filter(Time_Period_Start == "1999-07-01") %>%
  mutate(prop_death = sum_deaths/total_pop) %>%
  dplyr::select(State,
         sum_deaths,
         prop_death)


#make column of the lagged date
od_july_1999 <- od_july_1999 %>%
  mutate(lag_time_period_start = "2000-01-01")

#merge to original dataset
dih_dataset <- merge(dih_dataset, od_july_1999, 
                     by.x = c("State", "Time_Period_Start"), 
                     by.y = c("State", "lag_time_period_start"),
                     all.x = TRUE)

#fill in NA of lag_deaths with the sum_deaths and remove sum_deaths
dih_dataset <- dih_dataset %>%
  mutate(lag_deaths = coalesce(lag_deaths, sum_deaths),
         lag_prop_deaths = coalesce(lag_prop_deaths, prop_death)) %>%
  dplyr::select(-sum_deaths,
         -prop_death) %>%
  group_by(State) %>%
  mutate(lag_cum_sum_deaths = cumsum(lag_deaths),
         lag_cum_sum_prop_death = cumsum(lag_prop_deaths),
         log_prop_dead = log(prop_dead),
         log_lag_prop_deaths = log(lag_prop_deaths))

#since we lag the variables, the entry at time 1 will be NA. Since we have start dates of the different policies, I checked to 
#see which policies were enacted before Jan 1, 2000.
#if the policies were enacted before Jan 1, 2000, I impute a 1 for the first time period, otherwise a 0
dih_dataset$lag_tx[dih_dataset$Time_Period_ID == 1] <- 
  dih_dataset$lag_naloxone_pharm_yes[dih_dataset$Time_Period_ID == 1] <- 
  dih_dataset$lag_naloxone_pharm_no[dih_dataset$Time_Period_ID == 1] <-
  dih_dataset$lag_rec_marijuana[dih_dataset$Time_Period_ID == 1] <-
  dih_dataset$lag_gsl[dih_dataset$Time_Period_ID == 1] <-
  dih_dataset$lag_medicaid[dih_dataset$Time_Period_ID == 1] <- 
  dih_dataset$lag_intervention[dih_dataset$Time_Period_ID == 1]<-0

dih_dataset$lag_medical_marijuana[dih_dataset$Time_Period_ID == 1 &
                                   dih_dataset$State %in% 
                                   c("Alaska", "California", "Maine", "Oregon", "Washington")] <- 1
dih_dataset$lag_medical_marijuana[dih_dataset$Time_Period_ID == 1  &
                                   !(dih_dataset$State %in% 
                                       c("Alaska", "California", "Maine", "Oregon", "Washington"))] <- 0

dih_dataset$lag_pdmp[dih_dataset$Time_Period_ID == 1  &
                                   dih_dataset$State %in% 
                      c("California", "Hawaii", "Idaho", "Illinois", "Indiana", 
                        "Kentucky", "Massachusetts", "Michigan", "Nevada",
                        "New York", "Oklahoma", "Pennsylvania", "Rhode Island",
                        "Texas", "Utah", "West Virginia")] <- 1
dih_dataset$lag_pdmp[dih_dataset$Time_Period_ID == 1  &
                                   !(dih_dataset$State %in% 
                                       c("California", "Hawaii", "Idaho", "Illinois", "Indiana", 
                                         "Kentucky", "Massachusetts", "Michigan", "Nevada",
                                         "New York", "Oklahoma", "Pennsylvania", "Rhode Island",
                                         "Texas", "Utah", "West Virginia"))] <- 0

#create a new variable that indicates the number of policies that have been enacted by time t
dih_dataset$sum_lag_policies <- dih_dataset$lag_naloxone_pharm_yes + 
  dih_dataset$lag_naloxone_pharm_no + 
  dih_dataset$lag_medical_marijuana + 
  dih_dataset$lag_rec_marijuana + 
  dih_dataset$lag_gsl + 
  dih_dataset$lag_pdmp + 
  dih_dataset$lag_medicaid

#impute Hawaii's treatment date as something far off in the future
dih_dataset$Intervention_First_Date[dih_dataset$State == "Hawaii"] <- as.Date("9999-01-01")

```

# One Parameter Model: Binary Treatment Variable
## Mimicking Potential Outcomes
To compute the mimicked potential outcome: $H_{s,k}(t)$ for $k \in \{7-2019, \dotsc, 7-2000 \}$ and $t < k$, we first extract $Y_{s,k}$, where $Y_{s,k}$ is the log proportion of drug overdose death. We then compute $\gamma_t^k = exp(\psi*(a_{s,t} - a_{s,t-1}))$. Let $t_s^*$ be the treatment time interval for state $s$. We focus on data points for which $t \leq t_s^*$ and $t<k$. This is because for the treatment initiation model, we include data points for which $t \leq t_s^*$ and we want $t<k$. We let $a_{s,t}$ be a binary variable. For these data points we are intersted in, we create the variable `hkt` which is equal to $\frac{Y_{s,k}}{exp(\psi)}$ when $k > t_s^*$ (i.e. $Y_{s,k}$ is a treated outcome) and equal to $Y_{s,k}$ when $k \leq t_s^*$ (i.e. $Y_{s,k}$ is an untreated outcome). Lastly, we combine all these datapoints together for each $k$ into a dataset to be returned to use in the treatment initiation model.

```{r}
compute_mimick_potential_outcome <- function(dataFrame, gamma_k_t, outcome_variable){
  #dataFrame is the data frame input with the outcome variable, time points, states, treatment time
  #gamma_k_t is the function that we divide the hkt by if the unit is treated
  #outcome_variable is the variable name of the response
  
  #new_data_frame is the dataset we will return, with the new rows appended
  new_data_frame <- data.frame()
  
  #pull the treatment time period for the first treatment date
  tx_time_period_data <- dataFrame %>%
    filter(Time_Period_Start == floor_date(Intervention_First_Date, "6 months")) %>%
    dplyr::select(State, Time_Period_ID)
  
  #rename the Time_Period_ID to t_s since that is the treatment time
  colnames(tx_time_period_data) <- c("State", "t_s")
  
  #here, k is the time in which we observe the outcome and t is the time of the treatments
  #so we have k > t
  for(k in max(unique(dataFrame$Time_Period_ID)):2){
    #we first pull out the risk of OD at time k, so Y_k
    outcome_k_data <- dataFrame %>%
      arrange(State) %>%
      filter(Time_Period_ID == k) %>%
      dplyr::select(State, 
                    !!as.symbol(outcome_variable), 
                    Intervention_First_Date, 
                    Time_Period_Start)
    
    
    #merge tx_time_period_data with outcome_k_data
    #note: we have all.x = TRUE because we want all the rows in outcome_k_data since the date
    #for Hawaii is set to year 9999, so there are no matches
    outcome_k_data_with_tx_time_period <- merge(outcome_k_data, tx_time_period_data, by = "State",
                                                all.x = TRUE)
    
    #set t_s for Hawaii to be 9999
    outcome_k_data_with_tx_time_period$t_s[outcome_k_data_with_tx_time_period$State == "Hawaii"] <- 9999
    
    #compute k - t_s
    outcome_k_data_with_tx_time_period$k_minus_t_s <- k - outcome_k_data_with_tx_time_period$t_s
    
    
    #compute H_k(t) given gamma_k_t:
    #here, let t_s = treatment time 
    #if k <= t_s, then H_k(t) = Y_k since we havent treated yet, so doesn't affect
    #if t_s < t < k, then H_k(t) = Y_k since a_{t} - a_{t-1} = 0
    #if t <= t_s < k, then H_k(t) = Y_k/gamma_k_t
    outcome_k_data_with_tx_time_period$hkt <- ifelse(outcome_k_data_with_tx_time_period$k_minus_t_s > 0,
                                                     outcome_k_data_with_tx_time_period[,outcome_variable]/gamma_k_t, 
                                                     outcome_k_data_with_tx_time_period[,outcome_variable])
    
    
    #filter the data for which A_{s,t} = 0 and the time interval that contains the treatment time since we only need these data 
    #to predict treatment initiation for the model
    #we also filter so that the t < k
    untreated_and_first_tx_date_data <- dataFrame %>%
      arrange(State, Time_Period_ID) %>%
      #filter for t <= t_s because we use these time periods to predict treatment initiation
      filter(Time_Period_Start <= Intervention_First_Date,
             #filter for t < k
             Time_Period_ID < k)
    
    #merge the filtered dataset with the outcome_k_data_with_tx_time_period which contains the computed H_k(t)
    untreated_and_first_tx_date_data <- merge(untreated_and_first_tx_date_data, 
                                              outcome_k_data_with_tx_time_period[,c("State", "hkt", "t_s",
                                                                                    "k_minus_t_s")], by = "State")
    
    #add k and t to the dataset and the date of k
    untreated_and_first_tx_date_data$k <- k
    untreated_and_first_tx_date_data$date_k <- unique(outcome_k_data_with_tx_time_period$Time_Period_Start)

    #compute k - t
    untreated_and_first_tx_date_data$t <- untreated_and_first_tx_date_data$Time_Period_ID
    untreated_and_first_tx_date_data$k_minus_t <- k - untreated_and_first_tx_date_data$t
    
    #compute indicator of whether Y_{s,k} is treated outcome
    untreated_and_first_tx_date_data$treated_outcome_indicator <- untreated_and_first_tx_date_data$k_minus_t_s > 0

    #we then append the rows to the new_data_frame
    new_data_frame <- rbind(new_data_frame, untreated_and_first_tx_date_data)
  }
  new_data_frame
}


```

## Finding $\psi$: $\gamma_t^k = exp(\psi (a_t - a_{t-1}))$
Here, we assume that the treatment effects model is given by the one parameter model:
$$\gamma_t^k = exp(\psi*(a_t - a_{t-1})),$$
where $a_t$ and $a_{t-1}$ are binary variables (for now) indicating whether there have ever been any DIH prosecution media alerts by time $t$ and $t-1$. Further, we have $k > t_s^*$.

We fit a treatment initiation model for the response `dih_exposure` which is a binary variable indicating whether the state was exposed to DIH prosecution in the media, where we use the following as predictors:

* `sum_lag_policies` is the number of other policy measures that have been enacted from time 1 until time $t-1$
* `hkt` is the computed $H_k(t)$
* `Time_Period_ID` is the linear time effect.

Recall that the `analysis_data_with_hkt` only contains the datapoints for which $t \leq t^*$.
For each value $\psi$, we extract the coefficient of `hkt` from the treatment initiation model, and we find the $\psi$ that leads to a coefficient of zero. 
We also store a vector of `confidence_interval` which stores the values of $\psi$ if the Wald test for the coefficient of `hkt` is not statistically significant at the $alpha = 0.05$ level.

```{r}
#create a vector of 100 psi
# psi_grid_params <- seq(-0.1012847, -0.1012846, length.out = 100)
# psi_grid_params <- seq(-.2, .1, by = 0.001)
psi_grid_params <- seq(-1, 1, by = .01)
 #initialize the vector of coefficients for H(t) in treatment initiation model
coef_hkt <- rep(NA, length(psi_grid_params))
confidence_interval <- c()
for(grid_point in 1:length(psi_grid_params)){
  #statement to print the status of the for loop
  # if(grid_point%%10 == 0){print(grid_point)}
  #compute gamma_k_t given the psi_grid_params[grid_point]. Since here, the treatment is binary, we only need the value for
  #exp(psi_grid_params[grid_point])
  gamma_k_t <- exp(psi_grid_params[grid_point])

  #compute H(t) given the dataset and gamma_k_t
  analysis_data_with_hkt <- compute_mimick_potential_outcome(dih_dataset, gamma_k_t, "prop_dead")
 
  #fit model for treatment initiation
  treatment_initiation_model <- glm(dih_exposure~ 
                       sum_lag_policies + 
                       hkt +
                       lag_prop_deaths +   
                       Time_Period_ID,
                     data = analysis_data_with_hkt, family = "binomial")
  
  #store the coefficient for H_k(t)
  coef_hkt[grid_point] <- coef(treatment_initiation_model)["hkt"]
  
  #conduct the Wald Test for the third coefficient, which is H_k(t) here since the first coefficient is the intercept
  wald_test_results <- wald.test(vcov(treatment_initiation_model), coef(treatment_initiation_model), 3)
  #we then store the p-value and store the psi values if the p-value > 0.05
  pval <- wald_test_results$result$chi2["P"]
  if(pval > 0.05){
    confidence_interval <- rbind(confidence_interval, psi_grid_params[grid_point])
  }
}

# coef_hkt[90:91]
# psi_grid_params[90:91]
coef_hkt[90:91]
psi_grid_params[90:91]
as.vector(confidence_interval) 

#without past OD
#-0.022
#(-0.140, 0.083)

#with past OD
#-0.22
# (-0.40, -0.08)

#with past OD and probability of death in past
# -0.11 (-.21, -.02)

#with past OD and log probability of death in past
# 0.0066 (-0.0005 ,  0.0142)

#log probability past OD, Hkt is probability
# -0.1303734  (-0.25, -0.03)
```

When we did not include the past number of drug overdose deaths, the $\psi$ that produced an $\alpha(\psi)$, where $\alpha(\psi)$ is the coefficient of $H_k(t)$ in the treatment initiation model, that is closest to 0 is -0.022. The 95% Confidence Interval is (-0.140, 0.083).

When we included the past number of drug overdose deaths as the log of probability of drug overdose deaths into the treatment initiation model, the $\psi$ that produced an $\alpha(\psi)$, where $\alpha(\psi)$ is the coefficient of $H_k(t)$ in the treatment initiation model, that is closest to 0 is 0.0066. The 95% Confidence Interval is (-0.0005 ,  0.0142).


## Checking Grid-Search
Since we can compute the $\psi$ in a one-parameter model from the unbiased estimating equation, we do so to check the grid-search value.
We showed that 
$$E\left(\sum_s \sum_{k=1}^{T + 1} \sum_{t = 0}^{k-1} \vec{q}{_t}^{k}(\bar{X}_{s,t}, \bar{A}_{s,t-1}) H_{s,k}(t) \mathbb{I}\{\bar{A}_{s,t-1} = \bar{0}\}({g(A}_{s,t}) - \lambda_{s,t})\right) = 0.$$
We let $\vec{q}{_t}^{k}(\bar{X}_{s,t}, \bar{A}_{s,t-1}) = 1$ and $H_{s,k}(t) = \frac{Y_{s,k}}{exp(\psi)} \mathbb{I}\{k > t_s^*\} + Y_{s,k} \mathbb{I}\{k \leq t_s^*\}$ where $t_s^*$ is the treatment time for state $s$. Furthermore, we let $g(A_{s,t}) = \mathbb{I}\{A_{s,t} > 0\}$ and $\lambda_{s,t} = p_{s,t}$, the probability of treatment.
Then, we have the following:
\begin{align*}
  0 &= \sum_s \sum_{k=1}^{T + 1} \sum_{t = 0}^{k-1}  \left(\frac{Y_{s,k}}{exp(\psi)} \mathbb{I}\{k > t_s^*\} + Y_{s,k} \mathbb{I}\{k \leq t_s^*\}\right) \mathbb{I}\{\bar{A}_{s,t-1} = \bar{0}\}(\mathbb{I}\{A_{s,t} > 0\} - p_{s,t}) \\
  &= \sum_s \sum_{k=1}^{T + 1} \sum_{t = 0}^{k-1}  Y_{s,k}exp(-\psi) \mathbb{I}\{k > t_s^*\} \mathbb{I}\{\bar{A}_{s,t-1} = \bar{0}\}(\mathbb{I}\{A_{s,t} > 0\} - p_{s,t}) \\
  &+ \sum_s \sum_{k=1}^{T + 1} \sum_{t = 0}^{k-1} Y_{s,k} \mathbb{I}\{k \leq t_s^*\} \mathbb{I}\{\bar{A}_{s,t-1} = \bar{0}\}(\mathbb{I}\{A_{s,t} > 0\} - p_{s,t}) \\
  &\Rightarrow exp(-\psi) \sum_s \sum_{k=1}^{T + 1} \sum_{t = 0}^{k-1}  Y_{s,k} \mathbb{I}\{k > t_s^*\} \mathbb{I}\{\bar{A}_{s,t-1} = \bar{0}\}(\mathbb{I}\{A_{s,t} > 0\} - p_{s,t}) = -\sum_s \sum_{k=1}^{T + 1} \sum_{t = 0}^{k-1} Y_{s,k} \mathbb{I}\{k \leq t_s^*\} \mathbb{I}\{\bar{A}_{s,t-1} = \bar{0}\}(\mathbb{I}\{A_{s,t} > 0\} - p_{s,t}) \\
  &\Rightarrow exp(-\psi) = -\frac{\sum_s \sum_{k=1}^{T + 1} \sum_{t = 0}^{k-1} Y_{s,k} \mathbb{I}\{k \leq t_s^*\} \mathbb{I}\{\bar{A}_{s,t-1} = \bar{0}\}(\mathbb{I}\{A_{s,t} > 0\} - p_{s,t})}{\sum_s \sum_{k=1}^{T + 1} \sum_{t = 0}^{k-1}  Y_{s,k} \mathbb{I}\{k > t_s^*\} \mathbb{I}\{\bar{A}_{s,t-1} = \bar{0}\}(\mathbb{I}\{A_{s,t} > 0\} - p_{s,t})} \\
  &\Rightarrow \psi = - log\left(-\frac{\sum_s \sum_{k=1}^{T + 1} \sum_{t = 0}^{k-1} Y_{s,k} \mathbb{I}\{k \leq t_s^*\} \mathbb{I}\{\bar{A}_{s,t-1} = \bar{0}\}(\mathbb{I}\{A_{s,t} > 0\} - p_{s,t})}{\sum_s \sum_{k=1}^{T + 1} \sum_{t = 0}^{k-1}  Y_{s,k} \mathbb{I}\{k > t_s^*\} \mathbb{I}\{\bar{A}_{s,t-1} = \bar{0}\}(\mathbb{I}\{A_{s,t} > 0\} - p_{s,t})}\right),
\end{align*}
where we model $p_{s,t}$ using the `sum_lag_policies` and `Time_Period_ID` for data points in which $\bar{A}_{s,t-1} = \bar{0}$.
However, if the fraction is positive, then we arrive at an issue since we cannot take the log of a negative.

### With Weighted Original Dataset

```{r}
#filter the data to fit the treatment initiation model
dih_dataset_with_past_treatment_equals_0 <- dih_dataset %>%
  # filter data so that t < t_s + 1
  filter(Intervention_Redefined < 1)

#weights determined by how many periods until period 40
dih_dataset_with_past_treatment_equals_0$wt <- 40-dih_dataset_with_past_treatment_equals_0$Time_Period_ID

#fit the treatment initiation model
treatment_initiation_model <- glm(dih_exposure~
                                    sum_lag_policies + 
                                    lag_prop_deaths + 
                                    Time_Period_ID,
                                  data = dih_dataset_with_past_treatment_equals_0,
                                  family = "binomial",
                                  weights = wt)

# log_treatment_initiation_model <- glm(dih_exposure~
#                                     sum_lag_policies + 
#                                     log_lag_prop_deaths + 
#                                     Time_Period_ID,
#                                   data = dih_dataset_with_past_treatment_equals_0,
#                                   family = "binomial",
#                                   weights = wt)

#compute Y_{s,k} where periods k = 1, ..., T+1 for t = 0, ..., k-1
#to do this, we can use the compute_mimick_potential_outcome() function with gamma_k_t_when_treated as 1
#we also compute an indicator of whether k > t_s^* to indicate whether it is a treated outcome or untreated outcome
data_with_observed_Ysk <- compute_mimick_potential_outcome(dih_dataset, gamma_k_t = 1, "prop_dead")

data_with_observed_Ysk$prob_tx <- predict(treatment_initiation_model, newdata = data_with_observed_Ysk, type = "response")


#untreated outcome data to be used for numerator
untreated_outcome_data <- data_with_observed_Ysk[data_with_observed_Ysk$treated_outcome_indicator == FALSE,]
numerator <- sum(untreated_outcome_data$hkt*(untreated_outcome_data$dih_exposure - untreated_outcome_data$prob_tx))

#treated outcome data to be used for denominator
treated_outcome_data <- data_with_observed_Ysk[data_with_observed_Ysk$treated_outcome_indicator == TRUE,]
denominator <- sum(treated_outcome_data$hkt*(treated_outcome_data$dih_exposure - treated_outcome_data$prob_tx))

-log(-numerator/denominator)

#-0.261831
```

## Plot of Treatment Effect
```{r}
psi_lb <- -0.21
psi_ub <- -.02
psi_sol <- -0.11

total_psi_effect_one_param <- data.frame(time = 0:28,
                               sum_psi = psi_sol,
                               sum_psi_lb = psi_lb,
                               sum_psi_ub = psi_ub)


# pdf("./snmm/figures/one_param_effect_binary_tx_5_2_22.pdf")
ggplot(total_psi_effect_one_param, aes(x = time)) + 
  geom_line(aes(y = sum_psi, linetype = "Estimate")) + 
  geom_line(aes(y = sum_psi_lb, linetype = "95% CI")) + 
  geom_line(aes(y = sum_psi_ub, linetype = "95% CI"))+ 
  scale_linetype_manual(values = c("dashed", "solid")) + 
  labs(linetype = "",
       x = expression(k - t[s]^`*`),
       # title = expression(psi[1] + psi[2](k-t[s]^`*`)),
       y = expression(psi[1])) + 
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(), axis.line = element_line(colour = "black"),
        legend.position = "bottom") + 
  geom_hline(aes(yintercept = 0), color = "grey", linetype = "dotted")
# dev.off()

```

# Two Parameter Model: Binary Treatment
## Mimicking Potential Outcomes
To compute the mimicked potential outcome: $H_{s,k}(t)$ for $k \in \{7-2019, \dotsc, 7-2000 \}$ and $t < k$, we first extract $Y_{s,k}$. We then compute $\gamma_t^k = exp(\psi_1*(a_t - a_{t-1}) + \psi_2*(a_t - a_{t-1})*(k-t_s^*))$. Let $t_s^*$ be the treatment time interval for state $s$. We focus on data points for which $t \leq t_s^*$ and $t<k$. This is because for the treatment initiation model, we include data points for which $t \leq t_s^*$ and we want $t<k$. We let $a_{s,t}$ be a binary variable. For these data points we are interested in, we create the variable `hkt` which is equal to $\frac{Y_{s,k}}{exp(\psi_1 + \psi_2(k-t_s^*))}$ when $k > t_s^*$ (i.e. $Y_{s,k}$ is a treated outcome) and equal to $Y_{s,k}$ when $k \leq t_s^*$ (i.e. $Y_{s,k}$ is an untreated outcome). Lastly, we combine all these datapoints together for each $k$ into a dataset to be returned to use in the treatment initiation model.

```{r}
compute_mimick_potential_outcome_two_parameter_model <- function(dataFrame, psi_1, psi_2, outcome_variable){
  #dataFrame is the data frame input with the outcome variable, time points, states, treatment time
  #psi_1 is the first psi for the constant effect
  #psi_2 is the second psi for the effect dependent on how long state has been exposed
  #outcome_variable is the variable name of the response
  
  #new_data_frame is the dataset we will return, with the new rows appended
  new_data_frame <- data.frame()
  
  #pull the treatment time period for the first treatment date
  tx_time_period_data <- dataFrame %>%
    filter(Time_Period_Start == floor_date(Intervention_First_Date, "6 months")) %>%
    dplyr::select(State, Time_Period_ID)
  
  #rename the Time_Period_ID to t_s since that is the treatment time
  colnames(tx_time_period_data) <- c("State", "t_s")
  
  #here, k is the time in which we observe the outcome and t is the time of the treatments
  #so we have k > t
  for(k in max(unique(dataFrame$Time_Period_ID)):2){
    #we first pull out the risk of OD at time k, so Y_k
    outcome_k_data <- dataFrame %>%
      arrange(State) %>%
      filter(Time_Period_ID == k) %>%
      dplyr::select(State, 
                    !!as.symbol(outcome_variable), 
                    Intervention_First_Date, 
                    Time_Period_Start)
    
    
    #merge tx_time_period_data with outcome_k_data
    #note: we have all.x = TRUE because we want all the rows in outcome_k_data since the date
    #for Hawaii is set to year 9999, so there are no matches
    outcome_k_data_with_tx_time_period <- merge(outcome_k_data, tx_time_period_data, by = "State",
                                                all.x = TRUE)
    
    #set t_s for Hawaii to be 9999
    outcome_k_data_with_tx_time_period$t_s[outcome_k_data_with_tx_time_period$State == "Hawaii"] <- 9999
    
    #compute k - t_s
    outcome_k_data_with_tx_time_period$k_minus_t_s <- k - outcome_k_data_with_tx_time_period$t_s
    
    
    #compute H_k(t) given gamma_k_t:
    #here, let t_s = treatment time 
    #if k <= t_s, then H_k(t) = Y_k since we havent treated yet, so doesn't affect
    #if t_s < t < k, then H_k(t) = Y_k since a_{t} - a_{t-1} = 0
    #if t <= t_s < k, then H_k(t) = Y_k/gamma_k_t
    outcome_k_data_with_tx_time_period$hkt <- ifelse(outcome_k_data_with_tx_time_period$k_minus_t_s > 0,
                                                     outcome_k_data_with_tx_time_period[,outcome_variable]/
                                                       exp(psi_1 + psi_2*outcome_k_data_with_tx_time_period$k_minus_t_s), 
                                                     outcome_k_data_with_tx_time_period[,outcome_variable])
    
    
    #filter the data for which A_{s,t} = 0 and the time interval that contains the treatment time since we only need these data 
    #to predict treatment initiation for the model
    #we also filter so that the t < k
    untreated_and_first_tx_date_data <- dataFrame %>%
      arrange(State, Time_Period_ID) %>%
      #filter for t <= t_s because we use these time periods to predict treatment initiation
      filter(Time_Period_Start <= Intervention_First_Date,
             #filter for t < k
             Time_Period_ID < k)
    
    #merge the filtered dataset with the outcome_k_data_with_tx_time_period which contains the computed H_k(t)
    untreated_and_first_tx_date_data <- merge(untreated_and_first_tx_date_data, 
                                              outcome_k_data_with_tx_time_period[,c("State", "hkt", "t_s",
                                                                                    "k_minus_t_s")], by = "State")
    
    #add k and t to the dataset and the date of k
    untreated_and_first_tx_date_data$k <- k
    untreated_and_first_tx_date_data$date_k <- unique(outcome_k_data_with_tx_time_period$Time_Period_Start)

    #compute k - t
    untreated_and_first_tx_date_data$t <- untreated_and_first_tx_date_data$Time_Period_ID
    untreated_and_first_tx_date_data$k_minus_t <- k - untreated_and_first_tx_date_data$t
    
    #compute indicator of whether Y_{s,k} is treated outcome
    untreated_and_first_tx_date_data$treated_outcome_indicator <- untreated_and_first_tx_date_data$k_minus_t_s > 0

    #we then append the rows to the new_data_frame
    new_data_frame <- rbind(new_data_frame, untreated_and_first_tx_date_data)
  }
  new_data_frame
}




```


## Finding $\psi = (\psi_1, \psi_2)$: $\gamma_t^k = exp(\psi_1 (a_t - a_{t-1}) + \psi_2(a_t - a_{t-1})(k - t_s^*))$
Here, we assume that the treatment effects model is given by the two parameter model:
$$\gamma_t^k = exp(\psi_1*(a_t - a_{t-1}) + \psi_2 *(a_t - a_{t-1})*(k-t_s^*)),$$
where $a_t$ and $a_{t-1}$ are binary variables (for now) indicating whether there have ever been any DIH prosecution media alerts by time $t$ and $t-1$ and $k - t_s^*$ indicates the length of treatment. Further, we have $k > t_s^*$.

We fit a treatment initiation model for the response `dih_exposure` which is a binary variable indicating whether the state was exposed to DIH prosecution in the media, where we use the following as predictors:

* `sum_lag_policies` is the number of other policy measures that have been enacted from time 1 until time $t-1$
* `hkt` is the computed $H_k(t)$
* `hkt*sum_lag_policies` is the interaction between the $H_k(t)$ and the number of policy measures that have been enacted from time 1 until time $t-1$
* `Time_Period_ID` is the linear time effect.

Recall that the `analysis_data_with_hkt` only contains the datapoints for which $t \leq t^*$.
For each value $\psi$, we extract the coefficient of `hkt` from the treatment initiation model, and we find the $\psi$ that leads to a coefficient of zero. 
We also store a vector of `confidence_interval` which stores the values of $\psi$ if the Wald test for the coefficient of `hkt` and `hkt*sum_lag_policies` are not statistically significant at the $alpha = 0.05$ level.


## Grid-Search

```{r}
#################################
psi_grid_params_two_param <- expand.grid(psi_1 = seq(-.14,-.13,by = .001), psi_2 = seq(-.001,.005,by = .0001))
#initialize the vector of coefficients for H(t) in treatment initiation model
pval_grid_two_parameter <- coef_hkt_two_parameter <- rep(NA, nrow(psi_grid_params_two_param))
coef_hkt_sum_policy_two_parameter <- rep(NA, length(psi_grid_params_two_param))
confidence_interval_two_parameter <- data.frame()


for(grid_point in 1:nrow(psi_grid_params_two_param)){
  #statement to print the status of the for loop
  if(grid_point%%100 == 0){print(grid_point)}
  
  #compute H(t) given the dataset and gamma_k_t_when_treated
  analysis_data_with_hkt_two_parameter <- compute_mimick_potential_outcome_two_parameter_model(dih_dataset, 
                                                                                 psi_grid_params_two_param[grid_point,1], 
                                                                                 psi_grid_params_two_param[grid_point,2],
                                                                                 "prop_dead")
  
  #fit model for treatment initiation
  treatment_initiation_model_two_param <- glm(dih_exposure~ 
                                      sum_lag_policies + 
                                      hkt + 
                                      lag_prop_deaths + 
                                      Time_Period_ID + 
                                      hkt*sum_lag_policies,
                                    data = analysis_data_with_hkt_two_parameter, family = "binomial")
  
  #store the coefficient for H_k(t)
  coef_hkt_two_parameter[grid_point] <- coef(treatment_initiation_model_two_param)["hkt"]
  coef_hkt_sum_policy_two_parameter[grid_point] <- coef(treatment_initiation_model_two_param)["sum_lag_policies:hkt"]
  
  
  #don't do 95% CI yet -- wait until we figure out how to get psi_1, psi_2
  # #conduct the Wald Test for the third coefficient, which is H_k(t) here since the first coefficient is the intercept
  wald_test_results_two_parameter <- wald.test(vcov(treatment_initiation_model_two_param), 
                                               coef(treatment_initiation_model_two_param), Terms = c(3,6))
  # #we then store the p-value and store the psi values if the p-value > 0.05
  pval <- wald_test_results_two_parameter$result$chi2["P"]
  pval_grid_two_parameter[grid_point] <- pval
  if(pval > 0.05){
    confidence_interval_two_parameter <- rbind(confidence_interval_two_parameter, c(psi_grid_params_two_param[grid_point,1], 
                                                        psi_grid_params_two_param[grid_point,2]))
  }
  
}

colnames(confidence_interval_two_parameter) <- c("psi_1", "psi_2")

apply(confidence_interval_two_parameter, 2, min)
apply(confidence_interval_two_parameter, 2, max)

plot(pval_grid_two_parameter, ylab = "p-value")
pval_grid_two_parameter[pval_grid_two_parameter>0.98]
psi_grid_params_two_param[which(pval_grid_two_parameter>0.98),]
psi_grid_params_two_param[which.max(pval_grid_two_parameter),]
pval_grid_two_parameter[which.max(pval_grid_two_parameter)]

#psi1 = -0.132; psi_2 = 0.0009 with p-value 0.9999845
```

```{r}
psi_coef_data <- cbind(psi_grid_params_two_param, coef_hkt_two_parameter, coef_hkt_sum_policy_two_parameter)
colnames(psi_coef_data) <- c("psi_1", "psi_2", "coef_hkt", "coef_hkt_sum_policy")
# scatter3D(x = psi_coef_data$psi_1, y= psi_coef_data$psi_2, z = psi_coef_data$coef_hkt,  theta = 130, phi = 30,
#           xlab = "psi 1", ylab = "psi 2", zlab = "Coef of H_k_t")
# scatter3D(x = psi_coef_data$psi_1, y= psi_coef_data$psi_2, z = psi_coef_data$coef_hkt_sum_policy,  theta = 130, phi = 30,
#           xlab = "psi 1", ylab = "psi 2", zlab = "Coef of H_k_t*sum_policy")

#make a table where rows indicate psi_1 and columns indicate psi_2 and values are the coefficient values of H_{s,k}(t)
coef_hkt_mat <- matrix(NA, nrow = length(unique(psi_grid_params_two_param$psi_1)), 
                       ncol = length(unique(psi_grid_params_two_param$psi_2)))
rownames(coef_hkt_mat) <- unique(psi_grid_params_two_param$psi_1)
colnames(coef_hkt_mat) <- unique(psi_grid_params_two_param$psi_2)

#make a table where rows indicate psi_1 and columns indicate psi_2 and values are the coefficient values of H_{s,k}(t)*sum_policy
coef_hkt_mat_sum_policy <- matrix(NA, nrow = length(unique(psi_grid_params_two_param$psi_1)), 
                                  ncol = length(unique(psi_grid_params_two_param$psi_2)))
rownames(coef_hkt_mat_sum_policy) <- unique(psi_grid_params_two_param$psi_1)
colnames(coef_hkt_mat_sum_policy) <- unique(psi_grid_params_two_param$psi_2)

for(grid_point in 1:nrow(psi_coef_data)){
  coef_hkt_mat[as.character(psi_coef_data$psi_1[grid_point]), as.character(psi_coef_data$psi_2[grid_point])] <-
    psi_coef_data$coef_hkt[grid_point]
  coef_hkt_mat_sum_policy[as.character(psi_coef_data$psi_1[grid_point]), as.character(psi_coef_data$psi_2[grid_point])] <-
    psi_coef_data$coef_hkt_sum_policy[grid_point]
}
coef_hkt_mat
coef_hkt_mat_sum_policy

#save results
# write.csv(coef_hkt_mat, "./snmm/data/coef_hkt_mat_4_28_22_response_prop_dead_predictor_lag_prop_deaths.csv")
# write.csv(coef_hkt_mat_sum_policy, "./snmm/data/coef_hkt_sum_policy_mat_4_28_22_response_prop_dead_predictor_lag_prop_deaths.csv")

```

### Check Unbiased Estimating Equation
We first check that the values $\psi_1$ and $\psi_2$ solve the the unbiased estimating equations where $H_{s,k}(t)$ and $H_{s,k}(t)*$`sum_policy` are added to the treatment initiation model.

In the two-paramter model, the unbiased estimating equations are given by:
$$E\left(\sum_s \sum_{k=1}^{T + 1} \sum_{t = 0}^{k-1} \vec{q}{_t}^{k}(\bar{X}_{s,t}, \bar{A}_{s,t-1}) H_{s,k}(t) \mathbb{I}\{\bar{A}_{s,t-1} = \bar{0}\}({g(A}_{s,t}) - \lambda_{s,t})\right) = 0$$ and
$$E\left(\sum_s \sum_{k=1}^{T + 1} \sum_{t = 0}^{k-1} \vec{q}{_t}^{k}(\bar{X}_{s,t}, \bar{A}_{s,t-1}) H_{s,k}(t)*\sum_{p=1}^PX_{p,s,t-1} \mathbb{I}\{\bar{A}_{s,t-1} = \bar{0}\}({g(A}_{s,t}) - \lambda_{s,t})\right) = 0,$$
where $\sum_{p=1}^P X_{p,s,t-1}$ is equal to the number of relevant policies enacted before time $t$ or `sum_policy`.
We let $\vec{q}{_t}^{k}(\bar{X}_{s,t}, \bar{A}_{s,t-1}) = 1$ and $H_{s,k}(t) = \frac{Y_{s,k}}{exp(\psi_1 + \psi_2*(k - t_s^*))} \mathbb{I}\{k > t_s^*\} + Y_{s,k} \mathbb{I}\{k \leq t_s^*\}$ where $t_s^*$ is the treatment time for state $s$. Furthermore, we let $g(A_{s,t}) = \mathbb{I}\{A_{s,t} > 0\}$ and $\lambda_{s,t} = p_{s,t}$, the probability of treatment.

```{r}
psi_1_sol <- -0.132
psi_2_sol <- 0.0009

data_with_observed_Ysk_two_param <- compute_mimick_potential_outcome_two_parameter_model(dih_dataset, 
                                                                                         psi_1 = psi_1_sol, 
                                                                                         psi_2 = psi_2_sol,
                                                                                         "prop_dead")

#filter the data to fit the treatment initiation model
dih_dataset_with_past_treatment_equals_0 <- dih_dataset %>%
  # filter data so that t < t_s + 1
  filter(Intervention_Redefined < 1)

#weights determined by how many periods until period 40
dih_dataset_with_past_treatment_equals_0$wt <- 40-dih_dataset_with_past_treatment_equals_0$Time_Period_ID

#fit the treatment initiation model -- note this is the same as in the one-parameter model
treatment_initiation_model <- glm(dih_exposure~
                                    sum_lag_policies + 
                                    lag_prop_deaths + 
                                    Time_Period_ID,
                                  data = dih_dataset_with_past_treatment_equals_0,
                                  family = "binomial",
                                  weights = wt)

data_with_observed_Ysk_two_param$prob_tx <- predict(treatment_initiation_model, 
                                                    newdata = data_with_observed_Ysk_two_param, 
                                                    type = "response")

#untreated outcome data
untreated_outcome_data_two_param <- data_with_observed_Ysk_two_param[data_with_observed_Ysk_two_param$treated_outcome_indicator == FALSE,]

#treated outcome data 
treated_outcome_data_two_param <- data_with_observed_Ysk_two_param[data_with_observed_Ysk_two_param$treated_outcome_indicator == TRUE,]

#compute the estimating equation for hkt -- splitting into treated and untreated components
untreated_component_unbiased_est_eq_hkt_two_param <- sum(untreated_outcome_data_two_param$hkt*
                                                           (untreated_outcome_data_two_param$dih_exposure -
                                                                   untreated_outcome_data_two_param$prob_tx))

treated_component_unbiased_est_eq_hkt_two_param <- sum(treated_outcome_data_two_param$hkt*
                                                         (treated_outcome_data_two_param$dih_exposure -
                                                               treated_outcome_data_two_param$prob_tx))

untreated_component_unbiased_est_eq_hkt_two_param + treated_component_unbiased_est_eq_hkt_two_param

#compute the estimating equation for hkt*sum_policy -- splitting into treated and untreated components
untreated_component_unbiased_est_eq_hkt_sum_policy_two_param <- sum(untreated_outcome_data_two_param$hkt*
                                                                      untreated_outcome_data_two_param$sum_lag_policies*
                                                                      (untreated_outcome_data_two_param$dih_exposure -
                                                                         untreated_outcome_data_two_param$prob_tx))

treated_component_unbiased_est_eq_hkt_sum_policy_two_param <- sum(treated_outcome_data_two_param$hkt*
                                                                    treated_outcome_data_two_param$sum_lag_policies*
                                                                    (treated_outcome_data_two_param$dih_exposure -
                                                                       treated_outcome_data_two_param$prob_tx))

untreated_component_unbiased_est_eq_hkt_sum_policy_two_param + treated_component_unbiased_est_eq_hkt_sum_policy_two_param

```

## Grid-Search: Confidence Interval
```{r, eval = FALSE}
#################################
psi_grid_params_two_param <- expand.grid(psi_1 = seq(-1,.3,by = .01), psi_2 = seq(-.02,.03,by = .001))
#initialize the vector of coefficients for H(t) in treatment initiation model
pval_grid_two_parameter <- coef_hkt_two_parameter <- rep(NA, nrow(psi_grid_params_two_param))
coef_hkt_sum_policy_two_parameter <- rep(NA, length(psi_grid_params_two_param))
confidence_interval_two_parameter <- data.frame()


for(grid_point in 1:nrow(psi_grid_params_two_param)){
  #statement to print the status of the for loop
  if(grid_point%%100 == 0){print(grid_point)}
  
  #compute H(t) given the dataset and gamma_k_t_when_treated
  analysis_data_with_hkt_two_parameter <- compute_mimick_potential_outcome_two_parameter_model(dih_dataset, 
                                                                                 psi_grid_params_two_param[grid_point,1], 
                                                                                 psi_grid_params_two_param[grid_point,2],
                                                                                 "prop_dead")
  
  #fit model for treatment initiation
  treatment_initiation_model_two_param <- glm(dih_exposure~ 
                                      sum_lag_policies + 
                                      hkt + 
                                      lag_prop_deaths + 
                                      Time_Period_ID + 
                                      hkt*sum_lag_policies,
                                    data = analysis_data_with_hkt_two_parameter, family = "binomial")
  
  #store the coefficient for H_k(t)
  coef_hkt_two_parameter[grid_point] <- coef(treatment_initiation_model_two_param)["hkt"]
  coef_hkt_sum_policy_two_parameter[grid_point] <- coef(treatment_initiation_model_two_param)["sum_lag_policies:hkt"]
  
  
  #don't do 95% CI yet -- wait until we figure out how to get psi_1, psi_2
  # #conduct the Wald Test for the third coefficient, which is H_k(t) here since the first coefficient is the intercept
  wald_test_results_two_parameter <- wald.test(vcov(treatment_initiation_model_two_param), 
                                               coef(treatment_initiation_model_two_param), Terms = c(3,6))
  # #we then store the p-value and store the psi values if the p-value > 0.05
  pval <- wald_test_results_two_parameter$result$chi2["P"]
  pval_grid_two_parameter[grid_point] <- pval
  if(pval > 0.05){
    confidence_interval_two_parameter <- rbind(confidence_interval_two_parameter, c(psi_grid_params_two_param[grid_point,1], 
                                                        psi_grid_params_two_param[grid_point,2]))
  }
  
}

colnames(confidence_interval_two_parameter) <- c("psi_1", "psi_2")

apply(confidence_interval_two_parameter, 2, min)
apply(confidence_interval_two_parameter, 2, max)

plot(pval_grid_two_parameter, ylab = "p-value")
pval_grid_two_parameter[pval_grid_two_parameter>0.98]
psi_grid_params_two_param[which(pval_grid_two_parameter>0.98),]
psi_grid_params_two_param[which.max(pval_grid_two_parameter),]
pval_grid_two_parameter[which.max(pval_grid_two_parameter)]

#psi1 = -0.132; psi_2 = 0.0009 with p-value 0.9999845
#CI: psi_1: (-.94, .26); psi_2 = (-.013, 0.027)

pval_with_psis <- cbind(pval_grid_two_parameter, psi_grid_params_two_param)
colnames(pval_with_psis) <-c("pval", "psi_1", "psi_2")

# write.csv(pval_with_psis, "./snmm/data/confidence_interval_run_results_two_param_4_29_22_response_prop_dead_predictor_lag_prop_deaths_more_precise.csv", row.names = FALSE)

# pdf("./snmm/figures/pval_by_psi_1_two_param_4_29_22_response_prop_dead_predictor_lag_prop_deaths_more_precises.pdf")
ggplot(pval_with_psis, aes(x = psi_1, y = pval)) + 
  geom_point(color = "gray74") + 
  geom_hline(aes(yintercept = 0.05, , color = "alpha = 0.05", linetype = "alpha = 0.05")) + 
  geom_vline(aes(xintercept = -0.94, linetype = "95% CI", color = "95% CI")) + 
  geom_vline(aes(xintercept = 0.26, color = "95% CI", linetype = "95% CI")) +
  geom_vline(aes(xintercept = -0.132, color = "Estimate", linetype = "Estimate")) +
  labs(title = expression(paste("p-value by ", psi[1], sep = "")), 
       x = expression(psi[1]), 
       y = "p-value",
       color = "",
       linetype = "") +
  scale_linetype_manual(values = c("dashed", "dotted", "solid")) + 
  scale_color_manual(values = c("red", "blue", "black"))+ 
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(), axis.line = element_line(colour = "black"))
# dev.off()

# pdf("./snmm/figures/pval_by_psi_2_two_param_4_29_22_response_prop_dead_predictor_lag_prop_deaths_more_precise.pdf")
ggplot(pval_with_psis, aes(x = psi_2, y = pval)) + 
  geom_point(color = "gray74") + 
  geom_hline(aes(yintercept = 0.05, , color = "alpha = 0.05", linetype = "alpha = 0.05")) + 
  geom_vline(aes(xintercept = -0.013, linetype = "95% CI", color = "95% CI")) + 
  geom_vline(aes(xintercept = 0.027, color = "95% CI", linetype = "95% CI")) +
  geom_vline(aes(xintercept = 0.0009, color = "Estimate", linetype = "Estimate")) +
  labs(title = expression(paste("p-value by ", psi[2], sep = "")), 
       x = expression(psi[2]), 
       y = "p-value",
       color = "",
       linetype = "") +
  scale_linetype_manual(values = c("dashed", "dotted", "solid")) + 
  scale_color_manual(values = c("red", "blue", "black")) + 
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(), axis.line = element_line(colour = "black"))
# dev.off()

```

```{r}
pval_with_psis <- read.csv("./snmm/data/confidence_interval_run_results_two_param_4_29_22_response_prop_dead_predictor_lag_prop_deaths_more_precise.csv")

ggplot(pval_with_psis, aes(x = psi_1, y = pval)) + 
  geom_point(color = "gray74") + 
  geom_hline(aes(yintercept = 0.05, , color = "alpha = 0.05", linetype = "alpha = 0.05")) + 
  geom_vline(aes(xintercept = -0.94, linetype = "95% CI", color = "95% CI")) + 
  geom_vline(aes(xintercept = 0.26, color = "95% CI", linetype = "95% CI")) +
  geom_vline(aes(xintercept = -0.132, color = "Estimate", linetype = "Estimate")) +
  labs(title = expression(paste("p-value by ", psi[1], sep = "")), 
       x = expression(psi[1]), 
       y = "p-value",
       color = "",
       linetype = "") +
  scale_linetype_manual(values = c("dashed", "dotted", "solid")) + 
  scale_color_manual(values = c("red", "blue", "black"))+ 
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(), axis.line = element_line(colour = "black"))

ggplot(pval_with_psis, aes(x = psi_2, y = pval)) + 
  geom_point(color = "gray74") + 
  geom_hline(aes(yintercept = 0.05, , color = "alpha = 0.05", linetype = "alpha = 0.05")) + 
  geom_vline(aes(xintercept = -0.013, linetype = "95% CI", color = "95% CI")) + 
  geom_vline(aes(xintercept = 0.027, color = "95% CI", linetype = "95% CI")) +
  geom_vline(aes(xintercept = 0.0009, color = "Estimate", linetype = "Estimate")) +
  labs(title = expression(paste("p-value by ", psi[2], sep = "")), 
       x = expression(psi[2]), 
       y = "p-value",
       color = "",
       linetype = "") +
  scale_linetype_manual(values = c("dashed", "dotted", "solid")) + 
  scale_color_manual(values = c("red", "blue", "black")) + 
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(), axis.line = element_line(colour = "black"))

apply(pval_with_psis[pval_with_psis$pval > 0.05, ], 2, min)
apply(pval_with_psis[pval_with_psis$pval > 0.05, ], 2, max)
```

The estimated 95% confidence interval for $\psi_1$ is (-.94, .26) and the estimated 95% confidence interval for $\psi_2$ is (-.013, 0.027).


### Plot the $\psi_1$ and $\psi_2$
```{r}
psi_1_lb <- -0.94
psi_1_ub <- 0.26
psi_2_lb <- -0.013
psi_2_ub <- 0.027

total_psi_effect <- data.frame(time = 0:28,
                               sum_psi = psi_1_sol + psi_2_sol*c(0:28),
                               sum_psi_lb = psi_1_lb + psi_2_lb*c(0:28),
                               sum_psi_ub = psi_1_ub + psi_2_ub *c(0:28))


# pdf("./snmm/figures/two_param_effect_binary_tx_5_2_22.pdf")
ggplot(total_psi_effect, aes(x = time)) + 
  geom_line(aes(y = sum_psi, linetype = "Estimate")) + 
  geom_line(aes(y = sum_psi_lb, linetype = "95% CI")) + 
  geom_line(aes(y = sum_psi_ub, linetype = "95% CI"))+ 
  scale_linetype_manual(values = c("dashed", "solid")) + 
  labs(linetype = "",
       x = expression(k - t[s]^`*`),
       # title = expression(psi[1] + psi[2](k-t[s]^`*`)),
       y = expression(psi[1] + psi[2](k-t[s]^`*`))) + 
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(), axis.line = element_line(colour = "black"),
        legend.position = "bottom") + 
  geom_hline(aes(yintercept = 0), color = "grey", linetype = "dotted")
# dev.off()
```



# Count Model
```{r}
#create a plot for each state to see how many prosecution media alerts there are per 6 month period
#read in the prosecution media alert data
prosecution_data<-read.csv("./Data/dih_prosecutions_9_6_21.csv")

#data cleaning
prosecution_data<-prosecution_data %>% 
  mutate(Date = as.Date(Date.charged, "%m/%d/%Y")) %>%
  mutate(State = ifelse(State.Filed == "pennsylvania", "Pennsylvania", State.Filed),
         State = ifelse(State.Filed == "Virginia ", "Virginia", State)) %>%
  mutate(deceased_age = ifelse(!is.na(as.numeric(Deceased.s.Age)), as.numeric(Deceased.s.Age), 9999)) %>%
  filter(!is.na(Date), 
         State.Filed != "No Info", 
         State.Filed != "No info", 
         State.Filed != "No Info ",
         deceased_age >= 18,
         State != "" ) %>%
  mutate(deceased_age = ifelse(deceased_age == 9999, NA, deceased_age))

#clean up the data by looking at the link to the article
prosecution_data$Date[prosecution_data$Date == "2026-08-01"] <- as.Date("2016-02-15", "%Y-%m-%d")

#change the states into Character instead of factor
prosecution_data$State<-as.character(prosecution_data$State)
#see how many prosecution data points there are for each state
table(prosecution_data$State)

#there are some repeated cases depending on victim so extract distinct cases
prosecution_data_unique <- prosecution_data %>%
  group_by(State) %>%
  distinct(Accused.Name, Date, .keep_all = T)
table(prosecution_data_unique$State)

#change date charged into Date object
prosecution_data_unique$Date<-mdy(prosecution_data_unique$Date.charged)

#group the data into six month periods
prosecution_data_unique<-prosecution_data_unique %>% 
  mutate(six_month_pd = lubridate::floor_date(Date , "6 months" ))

prosecution_grouped <- prosecution_data_unique %>% 
  #filter to dates after 2000 and dates before 2020
  filter(year(six_month_pd) >= 2000 & year(six_month_pd) <= 2019) %>%
  group_by(State, six_month_pd) %>% 
  #for each state, for each six month period, count the number of DIH prosecutions
  summarise(num_dih = n())

dih_dataset_with_num_dih <- merge(dih_dataset, prosecution_grouped,
                                  by.x = c("State", "Time_Period_Start"),
                                  by.y = c("State", "six_month_pd"),
                                  all.x = TRUE)
#impute a 0 for the NAs
dih_dataset_with_num_dih$num_dih[is.na(dih_dataset_with_num_dih$num_dih)] <- 0

#create a column for the lag number of DIH prosecutions reported by media
dih_dataset_with_num_dih <- dih_dataset_with_num_dih %>%
  arrange(State, Time_Period_ID) %>%
  group_by(State) %>%
  mutate(lag_num_dih = lag(num_dih)) 

#assume that prior to the analysis period, there were no DIH prosecutions reported by media
dih_dataset_with_num_dih$lag_num_dih[dih_dataset_with_num_dih$Time_Period_ID == 1] <- 0

#compute the diff in number of DIH prosecutions
dih_dataset_with_num_dih$diff_num_dih <- dih_dataset_with_num_dih$num_dih - dih_dataset_with_num_dih$lag_num_dih

#plot the number of DIH prosecutions per state per time
# pdf("./snmm/figures/num_dih_by_state_5_1_22.pdf")
ggplot(dih_dataset_with_num_dih, aes(x = Time_Period_Start, y = num_dih)) + 
  facet_wrap(~State, scales = "free_y") + 
  # geom_point(aes(color = num_dih != 0), size = .5) + 
  geom_line() + 
  labs(color = "Non-zero DIH Prosecutions Reporeted by Media",
       x = "Date", 
       y = "Number of DIH Prosecutions Reported by Media") + 
  theme(legend.position = "bottom",
        axis.text.x = element_text(size = 4),
        axis.text.y = element_text(size = 6),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        strip.background = element_blank(),
        strip.text = element_text(size=6),
        panel.background = element_rect("white"))
# dev.off()

dih_dataset_with_num_dih %>%
  group_by(State) %>%
  summarise(mean_num_dih = mean(num_dih))
```

# One Parameter Model: Count Treatment Variable
## Mimicking Potential Outcomes
To compute the mimicked potential outcome: $H_{s,k}(t)$ for $k \in \{7-2019, \dotsc, 7-2000 \}$ and $t < k$, we first extract $Y_{s,k}$. We then compute $\gamma_t^k = exp(\psi*(a_{s,t} - a_{s,t-1}))$. Let $t_s^*$ be the treatment time interval for state $s$. We focus on data points for which $t \leq t_s^*$ and $t<k$. This is because for the treatment initiation model, we include data points for which $t \leq t_s^*$ and we want $t<k$. We let $a_{s,t}$ be the number of DIH prosecutions. For these data points we are interested in, we create the variable `hkt` which is equal to $\frac{Y_{s,k}}{exp(\psi*(a_{s,t} - a_{s,t-1}))}$ when $k > t_s^*$ (i.e. $Y_{s,k}$ is a treated outcome) and equal to $Y_{s,k}$ when $k \leq t_s^*$ (i.e. $Y_{s,k}$ is an untreated outcome). Lastly, we combine all these datapoints together for each $k$ into a dataset to be returned to use in the treatment initiation model.

```{r}
compute_mimick_potential_outcome_count <- function(dataFrame, psi, outcome_variable){
  #new_df is the dataset we will return, with the new rows appended
  #we initialize it first as the input dataset df
  new_data_frame <- data.frame()
  
  #pull the treatment time period for the first treatment date
  tx_time_period_data <- dataFrame %>%
    filter(Time_Period_Start == floor_date(Intervention_First_Date, "6 months")) %>%
    dplyr::select(State, Time_Period_ID)
  
  #rename the Time_Period_ID
  colnames(tx_time_period_data) <- c("State", "t_s")
  
  #here, k is the time in which we observe the outcome and t is the time of the treatments
  #so we have k > t
  for(k in max(unique(dataFrame$Time_Period_ID)):2){
    #we first pull out the risk of OD at time k, so Y_k
    outcome_k_data <- dataFrame %>%
      arrange(State) %>%
      filter(Time_Period_ID == k) %>%
      dplyr::select(State, 
                    !!as.symbol(outcome_variable), 
                    Intervention_First_Date, 
                    Time_Period_Start) %>%
      rename(ysk = !!as.symbol(outcome_variable))
    
    
    #merge it with outcome_k_data
    #note: we have all.x = TRUE because we want all the rows in outcome_k_data since the date
    #for Hawaii is set to year 9999, so there are no matches
    outcome_k_data_with_tx_time_period <- merge(outcome_k_data, tx_time_period_data, by = "State",
                                                all.x = TRUE)
    
    #set t_s for Hawaii to be 9999
    outcome_k_data_with_tx_time_period$t_s[outcome_k_data_with_tx_time_period$State == "Hawaii"] <- 9999
    
    #compute k - t_s^*
    outcome_k_data_with_tx_time_period$k_minus_t_s <- k - outcome_k_data_with_tx_time_period$t_s
    
    #initialize the value to be used to compute hkt for next time period
    hkt_helper_for_next_period <- outcome_k_data_with_tx_time_period[,c("ysk", "State")]
    colnames(hkt_helper_for_next_period) <- c("hkt_plus_1", "State")
    
    #now loop through t < k
    for(t in (k-1):1){
      #filter data to include only those with time t < k
      data_at_t <- dataFrame %>%
        filter(Time_Period_ID == t) 
      
      data_at_t <- merge(data_at_t, outcome_k_data_with_tx_time_period[,c("ysk", "t_s", "k_minus_t_s", "State")],
                             by = "State")
      
      #add hkt_plus_1 to data frame at time t, matching by State
      data_at_t <- merge(data_at_t, hkt_helper_for_next_period, by = "State")
      
      #compute H_k(t) given gamma_k_t:
      #here, let t^* = treatment time 
      #if k <= t^*, then H_k(t) = Y_k since we havent treated yet, so doesn't affect
      #if t^* < t < k, then H_k(t) = Y_k since a_{t} - a_{t-1} = 0
      #if t <= t^* < k, then H_k(t) = Y_k/gamma_k_t
      data_at_t$hkt <- ifelse(data_at_t$k_minus_t_s > 0,
                              data_at_t$hkt_plus_1/exp(psi*(data_at_t$diff_num_dih)), 
                              data_at_t$hkt_plus_1)
      
      #compute values that may be useful
      #add k and t to the dataset and the date of k
      data_at_t$k <- k
      data_at_t$date_k <- unique(outcome_k_data_with_tx_time_period$Time_Period_Start)
      data_at_t$t <- data_at_t$Time_Period_ID
      data_at_t$k_minus_t <- k - data_at_t$t
      
      #compute indicator of whether Y_{s,k} is treated outcome
      data_at_t$treated_outcome_indicator <- data_at_t$k_minus_t_s > 0
      
      #we then append the rows to the new_data_frame
      new_data_frame <- rbind(new_data_frame, data_at_t)
      
      #the value to be used to compute hkt for next time period
      hkt_helper_for_next_period <- data_at_t[,c("hkt", "State")]
      colnames(hkt_helper_for_next_period) <- c("hkt_plus_1", "State")
    }

  }
  new_data_frame
}

# compute_mimick_potential_outcome_count <- function(dataFrame, psi){
#   #new_df is the dataset we will return, with the new rows appended
#   #we initialize it first as the input dataset df
#   new_data_frame <- data.frame()
#   
#   #here, k is the time in which we observe the outcome and t is the time of the treatments
#   #so we have k > t
#   for(k in max(unique(dataFrame$Time_Period_ID)):2){
#     #we first pull out the risk of OD at time k, so Y_k
#     outcome_k_data <- dataFrame %>%
#       arrange(State) %>%
#       filter(Time_Period_ID == k) %>%
#       dplyr::select(State, log_prop_dead, Intervention_First_Date, Time_Period_Start) %>%
#       rename(ysk = log_prop_dead)
#     
#     #pull the treatment time period for the first treatment date
#     tx_time_period_data <- dataFrame %>%
#       filter(Time_Period_Start == floor_date(Intervention_First_Date, "6 months")) %>%
#       dplyr::select(State, Time_Period_ID)
#     
#     #rename the Time_Period_ID
#     colnames(tx_time_period_data) <- c("State", "t_s")
#     
#     
#     #merge it with outcome_k_data
#     #note: we have all.x = TRUE because we want all the rows in outcome_k_data since the date
#     #for Hawaii is set to year 9999, so there are no matches
#     outcome_k_data_with_tx_time_period <- merge(outcome_k_data, tx_time_period_data, by = "State",
#                                                 all.x = TRUE)
#     
#     #set t_s for Hawaii to be 9999
#     outcome_k_data_with_tx_time_period$t_s[outcome_k_data_with_tx_time_period$State == "Hawaii"] <- 9999
#     
#     #compute k - t_s^*
#     outcome_k_data_with_tx_time_period$k_minus_t_s <- k - outcome_k_data_with_tx_time_period$t_s
#     
#     #filter data to include only those with time t < k
#     data_before_k <- dataFrame %>%
#       filter(Time_Period_ID < k) 
#     
#     data_before_k <- merge(data_before_k, outcome_k_data_with_tx_time_period[,c("ysk", "t_s", "k_minus_t_s", "State")],
#                            by = "State")
#     
#     
#     #compute H_k(t) given gamma_k_t:
#     #here, let t^* = treatment time 
#     #if k <= t^*, then H_k(t) = Y_k since we havent treated yet, so doesn't affect
#     #if t^* < t < k, then H_k(t) = Y_k since a_{t} - a_{t-1} = 0
#     #if t <= t^* < k, then H_k(t) = Y_k/gamma_k_t
#     data_before_k$hkt <- ifelse(data_before_k$k_minus_t_s > 0,
#                                 data_before_k$ysk/exp(psi*(data_before_k$diff_num_dih)), 
#                                 data_before_k$ysk)
#     
#     
#     #compute values that may be useful
#     #add k and t to the dataset and the date of k
#     data_before_k$k <- k
#     data_before_k$date_k <- unique(outcome_k_data_with_tx_time_period$Time_Period_Start)
#     data_before_k$t <- data_before_k$Time_Period_ID
#     
#     
#     #compute k - t
#     data_before_k$k_minus_t <- k - data_before_k$t
#     #compute indicator of whether Y_{s,k} is treated outcome
#     data_before_k$treated_outcome_indicator <- data_before_k$k_minus_t_s > 0
#     
#     #we then append the rows to the new_data_frame
#     new_data_frame <- rbind(new_data_frame, data_before_k)
#   }
#   new_data_frame
# }



```

## Finding $\psi$: $\gamma_t^k = exp(\psi (a_t - a_{t-1}))$
Here, we assume that the treatment effects model is given by the one parameter model:
$$\gamma_t^k = exp(\psi*(a_t - a_{t-1})),$$
where $a_t$ and $a_{t-1}$ are count variables indicating whether there have ever been any DIH prosecution media alerts by time $t$ and $t-1$. Further, we have $k > t_s^*$.

We fit a treatment initiation model for the response `num_dih` which is a count variable indicating whether the state was exposed to DIH prosecution in the media, where we use the following as predictors:

* `sum_lag_policies` is the number of other policy measures that have been enacted from time 1 until time $t-1$
* `hkt` is the computed $H_k(t)$
* `log_lag_prop_death` is the log of the lagged proportion of drug overdose deaths
* `Time_Period_ID` is the linear time effect.

For each value $\psi$, we extract the coefficient of `hkt` from the treatment initiation model, and we find the $\psi$ that leads to a coefficient of zero. 
We also store a vector of `confidence_interval` which stores the values of $\psi$ if the Wald test for the coefficient of `hkt` is not statistically significant at the $alpha = 0.05$ level.

```{r, eval = FALSE}
#create a vector of 100 psi
# psi_grid_params <- seq(-0.1012847, -0.1012846, length.out = 100)
# psi_grid_params <- seq(-.2, .1, by = 0.001)
psi_grid_params_count <- seq(-3, 10, by = .5)
 #initialize the vector of coefficients for H(t) in treatment initiation model
coef_hkt_count <- rep(NA, length(psi_grid_params_count))
confidence_interval_count <- c()
for(grid_point in 1:length(psi_grid_params_count)){
  #statement to print the status of the for loop
  if(grid_point%%10 == 0){print(grid_point)}

  #compute H(t) given the dataset and gamma_k_t
  analysis_data_with_hkt_count <- compute_mimick_potential_outcome_count(dih_dataset_with_num_dih, 
                                                                         psi_grid_params_count[grid_point],
                                                                         "prop_dead")
 
  #fit model for treatment initiation
  treatment_initiation_model_count <- glm.nb(num_dih~ 
                       sum_lag_policies + 
                       hkt +
                       lag_prop_deaths +   
                       Time_Period_ID,
                     data = analysis_data_with_hkt_count)
  
  #store the coefficient for H_k(t)
  coef_hkt_count[grid_point] <- coef(treatment_initiation_model_count)["hkt"]
  
  #conduct the Wald Test for the third coefficient, which is H_k(t) here since the first coefficient is the intercept
  wald_test_results_count <- wald.test(vcov(treatment_initiation_model_count), coef(treatment_initiation_model_count), 3)
  #we then store the p-value and store the psi values if the p-value > 0.05
  pval_count <- wald_test_results_count$result$chi2["P"]
  if(pval_count > 0.05){
    confidence_interval_count <- rbind(confidence_interval_count, psi_grid_params_count[grid_point])
  }
}

coef_hkt_count[89:90]
psi_grid_params_count[89:90]
as.vector(confidence_interval_count)

#0.14
#CI: (-.0121, -0.0102)
```

When we included the past number of drug overdose deaths as the log of probability of drug overdose deaths into the treatment model, the $\psi$ that produced an $\alpha(\psi)$, where $\alpha(\psi)$ is the coefficient of $H_k(t)$ in the treatment model, that is closest to 0 is -0.011. The 95% Confidence Interval is (-.0121, -0.0102).


## Checking Grid-Search
Note we cannot just solve for $\psi$ from the unbiased estimating equations
We showed that 
$$E\left(\sum_s \sum_{k=1}^{T + 1} \sum_{t = 0}^{k-1} \vec{q}{_t}^{k}(\bar{X}_{s,t}, \bar{A}_{s,t-1}) H_{s,k}(t) \mathbb{I}\{\bar{A}_{s,t-1} = \bar{0}\}({g(A}_{s,t}) - \lambda_{s,t})\right) = 0.$$
We let $\vec{q}{_t}^{k}(\bar{X}_{s,t}, \bar{A}_{s,t-1}) = 1$ and $H_{s,k}(t) = \frac{\log Y_{s,k}}{exp(\psi*(a_{t} - a_{t-1}))} \mathbb{I}\{k > t_s^*\} + \log Y_{s,k} \mathbb{I}\{k \leq t_s^*\}$ where $Y_{s,k}$ is the probability of drug overdose death and $t_s^*$ is the treatment time for state $s$. Furthermore, we let $g(A_{s,t}) = A_{s,t}$ and $\lambda_{s,t} = \mu_{s,t}$, the mean number of DIH prosecutions.
Then, we have the following:
\begin{align*}
  0 &= \sum_s \sum_{k=1}^{T + 1} \sum_{t = 0}^{k-1}  \left(\frac{\log Y_{s,k}}{exp(\psi*(a_{t} - a_{t-1}))} \mathbb{I}\{k > t_s^*\} + \log Y_{s,k} \mathbb{I}\{k \leq t_s^*\}\right) \mathbb{I}\{\bar{A}_{s,t-1} = \bar{a}_{t-1}\}(A_{s,t} - \lambda_{s,t}) \\
  &= \sum_s \sum_{k=1}^{T + 1} \sum_{t = 0}^{k-1}  \log Y_{s,k}exp(-\psi*(a_{t} - a_{t-1}))\mathbb{I}\{k > t_s^*\} \mathbb{I}\{\bar{A}_{s,t-1} = \bar{a}_{t-1}\}(A_{s,t}  - \lambda_{s,t}) \\
  &+ \sum_s \sum_{k=1}^{T + 1} \sum_{t = 0}^{k-1} \log Y_{s,k} \mathbb{I}\{k \leq t_s^*\} \mathbb{I}\{\bar{A}_{s,t-1} = \bar{a}_{t-1}\}(A_{s,t} - \lambda_{s,t}),
\end{align*}
and we cannot isolate the $\psi$.
However, we can check the validity of our $\psi$ estimate using the unbiased estimating equation. 

```{r, eval = FALSE}
#compute Y_{s,k} where periods k = 1, ..., T+1 for t =0, ..., k-1
#to do this, we can use the compute_mimick_potential_outcome() function with gamma_k_t_when_treated as 1
#we also compute an indicator of whether k > t_s^* to indicate whether it is a treated outcome or untreated outcome
stacked_data_with_observed_Ysk_count <- compute_mimick_potential_outcome_count(dih_dataset_with_num_dih, psi = 0)

#psi from the grid search
psi_from_grid_search <- -0.011

treatment_initiation_model_stacked_data_count <- glm(num_dih~
                                                 sum_lag_policies + 
                                                 log_lag_prop_death +
                                                 Time_Period_ID,
                                               data = stacked_data_with_observed_Ysk_count,
                                               family = "poisson")

#store the p_{s,t}
stacked_data_with_observed_Ysk_count$est_mean_num_dih <- fitted(treatment_initiation_model_stacked_data_count)

#untreated outcome data to be used for numerator
untreated_outcome_stacked_data_count <- stacked_data_with_observed_Ysk_count[
  stacked_data_with_observed_Ysk_count$treated_outcome_indicator == FALSE,]
untreated_term_count<- sum(untreated_outcome_stacked_data$hkt*(untreated_outcome_stacked_data_count$num_dih - 
                                                       untreated_outcome_stacked_data_count$est_mean_num_dih))

#treated outcome data to be used for denominator
treated_outcome_stacked_data_count <- stacked_data_with_observed_Ysk_count[
  stacked_data_with_observed_Ysk_count$treated_outcome_indicator == TRUE,]
treated_term_count <- sum(treated_outcome_stacked_data_count$hkt*
                            (exp(-psi_from_grid_search*(treated_outcome_stacked_data_count$diff_num_dih)))*
                            (treated_outcome_stacked_data_count$num_dih - 
                                                       treated_outcome_stacked_data_count$est_mean_num_dih))

untreated_term_count + treated_term_count

#with lag number of deaths: -0.2242418
#with log lag proportion of deaths: -0.1303734
```


